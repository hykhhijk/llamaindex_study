{"docstore/metadata": {"cebe85fe-ba79-4b67-822d-add7854f3662": {"doc_hash": "09cf86244e6885d8cc757a47aac106da79e91141188080b3892ef89678131fea"}, "c156761d-6d08-4b17-b5f8-8ac6b6de0276": {"doc_hash": "81fb82252c96d4ad5abddb713e2d2fd5ef6e49a7b91781c08bcc9d16e8064533"}, "27921654-c1dc-4312-be04-6ae4d4194c21": {"doc_hash": "7b1e9830fcd97637d5e7db52cf3c7486c59186f04c1102a70a0e4718da8b88d7"}, "7f52e7ab-d4e2-4966-aa0d-c7514faecdb9": {"doc_hash": "594689f745ebdfb9cc49e17f1d601059ae265f2d86662c054101488564d4f75d"}, "9abc0300-2d8b-4b09-9df1-5e65fae7031d": {"doc_hash": "290169516ff3feb7a8970ada27e1fc39be9a423584531832253dbc01ce682be5"}, "a78419c4-2b31-4a00-b89b-92b1abc61c1c": {"doc_hash": "29e5926bf07ab45185332b24028abbb7f5fca96f470b87a45ef85d615bd9da6b"}, "d83d8b5f-4061-45d2-a27b-051694a59e76": {"doc_hash": "e200dbcb53cf229a693765274d0a4f47cc38fc7bc19316003c56a506b8fc95b9"}, "8247018b-9463-4da0-9106-b82b91c29fdd": {"doc_hash": "7ad554c70d685aeeb116d55f13e32ca7f1914a8d8f3c08d796274e043c4c08da"}, "48d4f33c-dd32-47fe-a421-30610383171d": {"doc_hash": "9be3ea2a829450677b881c9e8ec588984dca7a18213b442bbb2c77df748c59cb"}, "a0f6bf0c-0fec-4c71-a5e3-4157e1c0e377": {"doc_hash": "1efafc7a29a46748500af9d72fb3fa61fea5228a5f821a54a6a697f4e392efb3"}, "7907595d-1b6b-4d8f-b919-31bd87aac258": {"doc_hash": "4d4b89e1e97e1a76da599c83295a44b4905b31ceeae9986c00f8a0d7f1100987"}, "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0": {"doc_hash": "99c30108165f4694fa21dc44e2ee9d75ece6ff6e8e4d7bdfdd02c8490f72699a"}, "1b81acaa-761e-44c7-92ec-2cbe8675743b": {"doc_hash": "35f5e379f06c21d5a1f58165a55056e3c4c23a98e4f3a96642bf646d91441644"}, "40ee037e-52af-4da7-b433-f00011acab8d": {"doc_hash": "d98d1098b669d3b14419953afd4ea314a795c2f675d5b82716fe825922990f28"}, "234c40b0-589f-4ecd-a685-da31379e778e": {"doc_hash": "322bfde65ab95f3092f2a9107c73b55d92b50219389453d912b9d5579f3abee9"}, "6cb9cdaa-67ea-450a-b4af-b07280e51abf": {"doc_hash": "c8738356e376946f0e94b90840aa0cc27d4edadeb64d16ddc8ec845ba7ea6564"}, "a949a7f4-9c12-4e4c-b600-fc69affde3ce": {"doc_hash": "d9ea27eb54c7abd2da4bc25857b103cb7223bfab14c31f0fca91ecdf3cda3820"}, "b8f45ef9-0e05-4a12-add2-f9a866a51c97": {"doc_hash": "caa6cfb2332a03db468c27f8d22bc93488e1a7e2e7ed8f84d828462ae6b39cc2"}, "ed6723b5-7a1c-459f-b8a9-a02444c254c0": {"doc_hash": "58385fcb1daf586a949fb27d71a5e29bbb78174d1b23bf54aee86d1c35767f3d"}, "d170cc4a-480f-419d-9376-e0a822fc7458": {"doc_hash": "109f754f95c31ddc75b278bb101f840fb6bb3eca17c7ba23e6b61203156126c6"}, "fccb58ca-7e57-49dd-989b-831eed15e271": {"doc_hash": "5e0c8dcee58ec94a0f7216f44138cb6a347835e5021e8205165be00327578023"}, "cc432e08-65eb-41f6-9d68-9b24109c05a9": {"doc_hash": "867ec192a343fa9c2f1ebb2451a756bb0a879d8208942c9fa4faf3442f26b7e5"}, "cc17eec2-f6a5-4b74-af6a-6e4f184413fe": {"doc_hash": "aa27c89f5d58e590896772eb725c95f1e1c796e3e32e4090149c6248837de26e"}, "3ce66208-b3c9-4911-9373-8a7d8db74d6b": {"doc_hash": "b15cfd353e32c2259a9f2eafb52431eb464ef3f6e6c8c229c92ba618bcb637c6"}, "32d99d0a-a883-4932-bd68-796626301497": {"doc_hash": "33ec8af463bf2faab696c739432b841e61a46548a6d4a0e5f97c0beec2df369c"}, "f6362649-cbf2-4cbe-ba03-7229ff831607": {"doc_hash": "196a41719e9cb0f289c4d8cf706db3de847009b6f977b2892352b3312c5d2d6d", "ref_doc_id": "cebe85fe-ba79-4b67-822d-add7854f3662"}, "014040ad-8955-42b6-afc8-c69c6f43911c": {"doc_hash": "c42a2132938c161e379bc5592f50c9becf2e5882e4fd4abed636f4363d14bb2c", "ref_doc_id": "cebe85fe-ba79-4b67-822d-add7854f3662"}, "7db1ce10-c1aa-4c40-81eb-2a3c191205c3": {"doc_hash": "ea4acb9c9c2648c02c381164fdb0beca1e15f4e3cc8e6df23364fbf3d20e5a2c", "ref_doc_id": "c156761d-6d08-4b17-b5f8-8ac6b6de0276"}, "d95d335d-6b34-4b88-9485-94a259d7824f": {"doc_hash": "c37ed0e7f4fbfd6cc472cb7bfd91269bf374053626116394ebd44696f2c3df55", "ref_doc_id": "c156761d-6d08-4b17-b5f8-8ac6b6de0276"}, "72464c0d-fe36-42b7-8899-75c35c07db57": {"doc_hash": "59a209981afe880df5a4b3ba58f2fb6fb9d02800c712da1b3c12ee9a920e4fd4", "ref_doc_id": "27921654-c1dc-4312-be04-6ae4d4194c21"}, "7e872be7-e989-4e10-ad12-d367dddf2b0f": {"doc_hash": "f0d59a25494eafe06da139058472b847712912e917a80a3de128119b81fc04a9", "ref_doc_id": "27921654-c1dc-4312-be04-6ae4d4194c21"}, "5a27f4bc-4aff-4ddf-bd4c-e575d3b28aa4": {"doc_hash": "7705b705966f9f343e02a0adbeeb2acc67c82c00c02236dd0f42c35518d545d5", "ref_doc_id": "27921654-c1dc-4312-be04-6ae4d4194c21"}, "67c39bfd-203e-4b3e-b6f1-9df456f647e1": {"doc_hash": "74fc3a51497eb903fde231693ed38191c2e0fbeb707bb8c7f079796784b9b8f6", "ref_doc_id": "7f52e7ab-d4e2-4966-aa0d-c7514faecdb9"}, "70d0bc64-5709-4f15-a3f6-328c702f3ebc": {"doc_hash": "57acc16e0c832a549f3ff1044f6db14234a30e6e389b635f26f4dcc4c0311714", "ref_doc_id": "7f52e7ab-d4e2-4966-aa0d-c7514faecdb9"}, "9ba321d5-9acb-4d76-b38a-d235a32fdb5c": {"doc_hash": "2415ca8b25e2262ae359aca6e6d1927e3fb6781358f190db254dbdd27508b2de", "ref_doc_id": "9abc0300-2d8b-4b09-9df1-5e65fae7031d"}, "325ed854-9ad8-4022-a0c7-252b93486ae2": {"doc_hash": "bfd7c25683a268de03ff19c7972fa236b9352133dc346daea74f508bd58a0cd2", "ref_doc_id": "9abc0300-2d8b-4b09-9df1-5e65fae7031d"}, "caafb3d4-a155-469f-b40f-ddc38ed38242": {"doc_hash": "0d250f3fbd37f740d52cc71a472a1df605918413e9757e61e03d787ba46453ed", "ref_doc_id": "9abc0300-2d8b-4b09-9df1-5e65fae7031d"}, "576440ce-d9b2-4152-8215-02be62c9295c": {"doc_hash": "7425b5b3767a480e8a2da21c3a348947f2968953b201577569347f3aa195d661", "ref_doc_id": "a78419c4-2b31-4a00-b89b-92b1abc61c1c"}, "33e9f339-0f4e-48ad-b229-44948c014104": {"doc_hash": "caa836595957a6bf05e666bfbd50f62700368442ee6d473022e3620f634604ad", "ref_doc_id": "a78419c4-2b31-4a00-b89b-92b1abc61c1c"}, "4c41ca3e-a5a4-473e-9023-4b41970a634a": {"doc_hash": "d73fb508107f2c78f61302d46387a500184410e27a0e7ca9c0d16ff0d6efacf8", "ref_doc_id": "d83d8b5f-4061-45d2-a27b-051694a59e76"}, "15a9cd10-9747-4034-b731-67c2d883f805": {"doc_hash": "3b1c2e55c00e4b4a71386630fc5d85247e030d2231d11cb179be8748835af06f", "ref_doc_id": "d83d8b5f-4061-45d2-a27b-051694a59e76"}, "aac6013d-e349-416f-95e5-64cd6eaa80e6": {"doc_hash": "c56b3290269e4783e061768aa7341dd0864bec851b98af30dd0e29cfea779eb0", "ref_doc_id": "8247018b-9463-4da0-9106-b82b91c29fdd"}, "c13636e0-5a27-4e10-9957-ec1131a7b208": {"doc_hash": "ae94a2ebb964d4631b54af1e24c6abb2a03797876e79482b53352eafbe4d1c4a", "ref_doc_id": "8247018b-9463-4da0-9106-b82b91c29fdd"}, "067d87de-26c6-47f8-99eb-99e2c7255460": {"doc_hash": "07bc5d3a1836ff2415b5c35683027315cddee7bbdeaf7dbc60d0669941784b38", "ref_doc_id": "8247018b-9463-4da0-9106-b82b91c29fdd"}, "4a51c20c-d4c0-4a4d-b596-1cb67c1ca20b": {"doc_hash": "7ec2e1fa4262a50947efe4d50bf901137344d6ccc11f182db445f6f492afc019", "ref_doc_id": "48d4f33c-dd32-47fe-a421-30610383171d"}, "721baf6a-39ca-49ba-9f89-060af35d177e": {"doc_hash": "9c1347f7749164b0e4f88f819c0ec3cca80c3a07da9ed150bdd8289adb996326", "ref_doc_id": "48d4f33c-dd32-47fe-a421-30610383171d"}, "7e13a176-2568-4dd0-a36c-a1f66c2c4510": {"doc_hash": "a9db182be4b93d9d0ae6827501da711b1b02941621337b1e0da5a321eb834703", "ref_doc_id": "48d4f33c-dd32-47fe-a421-30610383171d"}, "17a21ccf-d2e1-4871-b4c5-8e4469a9daaf": {"doc_hash": "a82885934a0236120de8ee2e1704dbfa76c5d97bb6a8cbeb660d218bbf29ed4c", "ref_doc_id": "a0f6bf0c-0fec-4c71-a5e3-4157e1c0e377"}, "61a1b29f-ec49-4fc7-a321-83037fe8f747": {"doc_hash": "ad19c9658430e84c056b5010a630c3e9aa3e7fd5dc48b37c8e2c0ca313b1b79c", "ref_doc_id": "a0f6bf0c-0fec-4c71-a5e3-4157e1c0e377"}, "cf4e458f-2ca1-4fd0-8cc9-7243f98a95d5": {"doc_hash": "bbf2485fde5497e5f13291b4b2e3eb67fd968baf19f2d74f51595e151bba655b", "ref_doc_id": "7907595d-1b6b-4d8f-b919-31bd87aac258"}, "4bf37bb2-484b-4415-94d2-d24f4d2d9cf4": {"doc_hash": "6202af85a9632d177d20dd93cf89b59e25feb5eda023afa74fb5e802cac72f75", "ref_doc_id": "7907595d-1b6b-4d8f-b919-31bd87aac258"}, "ada23e72-1c0f-4d38-a09f-14693e90aeb9": {"doc_hash": "67d88c9f1b3a407f04af7c9d8f1301a203ff86b971471edf55c4815cb6a602ea", "ref_doc_id": "7907595d-1b6b-4d8f-b919-31bd87aac258"}, "2de8a8ae-2cf2-4517-b676-7ad597fa45d2": {"doc_hash": "84246c282e1b45d61f75413cae7327665188c3dac03a1869d2edcf4850e967f5", "ref_doc_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0"}, "5e0d7472-f62f-406b-b43f-faa42fc4683b": {"doc_hash": "9b6507e32f6b42b86537a8edd5f737843ff3ab7bb1b1a97e6e457c5f83d2709a", "ref_doc_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0"}, "80d80fec-a578-4e90-99e2-8bfcc85ec207": {"doc_hash": "7b1788157214b241530a624720018b5ac3b962ffa941c8dda3b4e7ae6fb1d92d", "ref_doc_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0"}, "3140db75-6905-4826-a178-da5318de796e": {"doc_hash": "c07d89cf62d929d50166cd9537cfe78a46c2a90c7a75f12edd7f50bad4badd51", "ref_doc_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0"}, "7e80259e-3cc1-4133-b552-80263eec164a": {"doc_hash": "95f1967dcf1675aa029294bef5d4bf7c87ced85323cabd4d977abadbb73c5322", "ref_doc_id": "1b81acaa-761e-44c7-92ec-2cbe8675743b"}, "b5dd3fe9-6ada-4e1b-b168-0a8bc36d47a8": {"doc_hash": "6b3c4ace3a19ea08c47cd3684646d23f799af0ae1f2dc03d8b0062cd087168a3", "ref_doc_id": "1b81acaa-761e-44c7-92ec-2cbe8675743b"}, "19058b0e-1e94-4a99-9eae-c8f8f07dce83": {"doc_hash": "b0383e2d3cc8e7b1db245021b3af8b5a407a3d328b2056357ca364134b5f2a07", "ref_doc_id": "1b81acaa-761e-44c7-92ec-2cbe8675743b"}, "979d53bd-b996-4067-9c75-2d6311d1cc52": {"doc_hash": "51d855502a7cd4fd7076d15884f70737671e3705c7824ef51c4273426af18c73", "ref_doc_id": "40ee037e-52af-4da7-b433-f00011acab8d"}, "831dec67-ed67-41d7-aa5d-28199b50d00a": {"doc_hash": "b4c469b758f26c4d02803f4fd401cab7c5f0f21565f3bce6bc3bdfd9244bce1d", "ref_doc_id": "40ee037e-52af-4da7-b433-f00011acab8d"}, "e2667920-a83d-457e-8c7b-74d65e73358e": {"doc_hash": "bfb942ede334a2f1e1a201ac6c719179e7b4f4d8afad3cafe56f7430687cfda9", "ref_doc_id": "40ee037e-52af-4da7-b433-f00011acab8d"}, "e9c19ca0-dbb0-4608-8628-3beb7e822fd8": {"doc_hash": "7114133fcca04b9610075118c16cf3a7b2d6ff4172eec8e00d2c71271956096e", "ref_doc_id": "234c40b0-589f-4ecd-a685-da31379e778e"}, "3891e37a-b49d-43ec-8529-c4b23f6ded5d": {"doc_hash": "dd64ff3934fdc276157bddb769cd7f3f0870f82142b5b3904dbc7ee1a8b0f8e3", "ref_doc_id": "234c40b0-589f-4ecd-a685-da31379e778e"}, "6d645c9e-e77e-4ccd-be3a-3b5fec5f0cbc": {"doc_hash": "801ba71604aa924152bfed89b26d05d2358c2a26030b75889e09035436d0fbd9", "ref_doc_id": "234c40b0-589f-4ecd-a685-da31379e778e"}, "602c45a8-34ed-4c9d-8360-e061daaded0f": {"doc_hash": "951351298a8ab78ff4e9697e30be34533b8fa49f476e416716cb7963d95a7792", "ref_doc_id": "234c40b0-589f-4ecd-a685-da31379e778e"}, "946056b5-0b10-4bf3-a8de-607f5faedfa8": {"doc_hash": "853d5ec9b08a6792014f5711f1ff68b63c98b244a656e888c72e30bc2b8cb7ab", "ref_doc_id": "6cb9cdaa-67ea-450a-b4af-b07280e51abf"}, "46233c45-41ff-42ba-b24c-255ec301b738": {"doc_hash": "9bcf46e180434a7b83222e6d4aad7d8206cc8e04abb511a552ef91ab82d70952", "ref_doc_id": "6cb9cdaa-67ea-450a-b4af-b07280e51abf"}, "542022e0-535a-4367-8845-affcda1d2f63": {"doc_hash": "c71d1a43772e0784723edef642ae119f433a08b3c0bd58c9609dbd00e3c5f045", "ref_doc_id": "6cb9cdaa-67ea-450a-b4af-b07280e51abf"}, "dd0a4a21-7a9b-4ea5-88b0-d927294f8827": {"doc_hash": "4d59cd9c83e7f1e1de9638664ba54cea5f601cbef4aa515d77a2e93668a04a58", "ref_doc_id": "a949a7f4-9c12-4e4c-b600-fc69affde3ce"}, "0186f0a7-3712-449c-9d45-85e479b42831": {"doc_hash": "86424e841158b6b65095e3f8539d21c6aef4ab1dc529212202e7daeb5fa67b95", "ref_doc_id": "a949a7f4-9c12-4e4c-b600-fc69affde3ce"}, "c48bf46e-d1c3-42b0-bd70-71009c65d1e1": {"doc_hash": "9ccdecaea1e39dc77b4c5855cbb857fc9b1301aefd34a200a6b5b38d6aac264c", "ref_doc_id": "b8f45ef9-0e05-4a12-add2-f9a866a51c97"}, "564c86aa-edfb-4a58-91f3-231d689f482c": {"doc_hash": "c1f4a7c6524a20af7bf35609fe9a37b742d12e5d03104c85918d89a97fd947ae", "ref_doc_id": "b8f45ef9-0e05-4a12-add2-f9a866a51c97"}, "7c7caf75-486d-4906-a929-7dce5813c76c": {"doc_hash": "bfdec56060ce2d9e3cf669f6f3e0814b5f076c74b9069e90a84133493f6f1c35", "ref_doc_id": "ed6723b5-7a1c-459f-b8a9-a02444c254c0"}, "c7b9e4eb-a344-4de6-92ee-f7728e64223e": {"doc_hash": "f595d291ff0530894f51c17e85add168ae99c558ccde4c6cac7f4a8b083e2adf", "ref_doc_id": "d170cc4a-480f-419d-9376-e0a822fc7458"}, "bce3975b-dd9a-4456-8b4c-834c86790df9": {"doc_hash": "9eaef192991ce7560715b067b95a4bab239dd40c67227197212bf95fdec37883", "ref_doc_id": "d170cc4a-480f-419d-9376-e0a822fc7458"}, "6c7ae6ed-40f5-4a0c-a7ef-2c50dc2f5414": {"doc_hash": "4e6692a36082248373a9caab4d2d7e79f7597bd7871b5f8d14731331fcf4bc30", "ref_doc_id": "d170cc4a-480f-419d-9376-e0a822fc7458"}, "e36c5740-185a-4baf-bf72-2c5e15581d80": {"doc_hash": "4adc8c895849b5ca9c9d33c46ebfe2c0fac2ca6f3e6def7175685fa4f3d1804e", "ref_doc_id": "d170cc4a-480f-419d-9376-e0a822fc7458"}, "a2944bdd-1ba4-40eb-9fc9-cef6a660039b": {"doc_hash": "1e42f765ff5ddd796e72f8453cbf2e4722a41aac89317a8e2e095a8a68586b61", "ref_doc_id": "fccb58ca-7e57-49dd-989b-831eed15e271"}, "cf89f48b-46ab-4a30-aad0-e77d4b8fe471": {"doc_hash": "9b6255c39a35d1f6066afa5cf24b7e159c70bb2e1eb22e341bf86b44c8ca349d", "ref_doc_id": "fccb58ca-7e57-49dd-989b-831eed15e271"}, "97de8706-944d-4adb-b275-4f8a65a7eb4e": {"doc_hash": "ba343c3c7e429340eef704147a313b0782f618d90eccefc539619cf74e2d5b42", "ref_doc_id": "fccb58ca-7e57-49dd-989b-831eed15e271"}, "1af9fa12-5185-4c5c-b872-90331da112b1": {"doc_hash": "e93ae99283af091307d32a04745a0c6843831d900382a16d835ac3f8b634f6e5", "ref_doc_id": "fccb58ca-7e57-49dd-989b-831eed15e271"}, "47934842-e923-436f-98aa-5c890314a2c2": {"doc_hash": "8efa97e4b9f8f507a7d2c7fd995fce5dc7b01c23cabad8297b7e59f20e0bad60", "ref_doc_id": "cc432e08-65eb-41f6-9d68-9b24109c05a9"}, "f08ab8f4-6f73-4106-be4b-f39ee7804501": {"doc_hash": "5bb9b0a67008cdd3e83666bbc827f629f2c1c59847e6d6e72e8a2ac5f125fc14", "ref_doc_id": "cc432e08-65eb-41f6-9d68-9b24109c05a9"}, "46bac1e0-24f2-47b7-bcc4-2658e48bb970": {"doc_hash": "73f4c842b02ffe8a19e92f9befc8161bba38dfaf7c746a0d82365ebd522ca41b", "ref_doc_id": "cc17eec2-f6a5-4b74-af6a-6e4f184413fe"}, "8d4f9b2b-18bc-488c-bd53-74d4298adf19": {"doc_hash": "0fb1a8cb9bbfa67f28f0063106d57f90a57af14d970eeafef14790a407d86792", "ref_doc_id": "cc17eec2-f6a5-4b74-af6a-6e4f184413fe"}, "db72b9e5-8186-4e5f-ad4b-89526c81d05a": {"doc_hash": "332b65093c26a8603741a96ac64b6ab7af50a5c5d1bec1abb0cd7bae4b8d4bb9", "ref_doc_id": "3ce66208-b3c9-4911-9373-8a7d8db74d6b"}, "6228812a-e038-4e41-8a4c-c577a413d771": {"doc_hash": "5e69a30f590a32cf0e5bd4d7276309d7988e6158671fb8d45d277e17e072b0ec", "ref_doc_id": "32d99d0a-a883-4932-bd68-796626301497"}}, "docstore/ref_doc_info": {"cebe85fe-ba79-4b67-822d-add7854f3662": {"node_ids": ["f6362649-cbf2-4cbe-ba03-7229ff831607", "014040ad-8955-42b6-afc8-c69c6f43911c"], "metadata": {"page_label": "1", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "c156761d-6d08-4b17-b5f8-8ac6b6de0276": {"node_ids": ["7db1ce10-c1aa-4c40-81eb-2a3c191205c3", "d95d335d-6b34-4b88-9485-94a259d7824f"], "metadata": {"page_label": "2", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "27921654-c1dc-4312-be04-6ae4d4194c21": {"node_ids": ["72464c0d-fe36-42b7-8899-75c35c07db57", "7e872be7-e989-4e10-ad12-d367dddf2b0f", "5a27f4bc-4aff-4ddf-bd4c-e575d3b28aa4"], "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "7f52e7ab-d4e2-4966-aa0d-c7514faecdb9": {"node_ids": ["67c39bfd-203e-4b3e-b6f1-9df456f647e1", "70d0bc64-5709-4f15-a3f6-328c702f3ebc"], "metadata": {"page_label": "4", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "9abc0300-2d8b-4b09-9df1-5e65fae7031d": {"node_ids": ["9ba321d5-9acb-4d76-b38a-d235a32fdb5c", "325ed854-9ad8-4022-a0c7-252b93486ae2", "caafb3d4-a155-469f-b40f-ddc38ed38242"], "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "a78419c4-2b31-4a00-b89b-92b1abc61c1c": {"node_ids": ["576440ce-d9b2-4152-8215-02be62c9295c", "33e9f339-0f4e-48ad-b229-44948c014104"], "metadata": {"page_label": "6", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "d83d8b5f-4061-45d2-a27b-051694a59e76": {"node_ids": ["4c41ca3e-a5a4-473e-9023-4b41970a634a", "15a9cd10-9747-4034-b731-67c2d883f805"], "metadata": {"page_label": "7", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "8247018b-9463-4da0-9106-b82b91c29fdd": {"node_ids": ["aac6013d-e349-416f-95e5-64cd6eaa80e6", "c13636e0-5a27-4e10-9957-ec1131a7b208", "067d87de-26c6-47f8-99eb-99e2c7255460"], "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "48d4f33c-dd32-47fe-a421-30610383171d": {"node_ids": ["4a51c20c-d4c0-4a4d-b596-1cb67c1ca20b", "721baf6a-39ca-49ba-9f89-060af35d177e", "7e13a176-2568-4dd0-a36c-a1f66c2c4510"], "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "a0f6bf0c-0fec-4c71-a5e3-4157e1c0e377": {"node_ids": ["17a21ccf-d2e1-4871-b4c5-8e4469a9daaf", "61a1b29f-ec49-4fc7-a321-83037fe8f747"], "metadata": {"page_label": "10", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "7907595d-1b6b-4d8f-b919-31bd87aac258": {"node_ids": ["cf4e458f-2ca1-4fd0-8cc9-7243f98a95d5", "4bf37bb2-484b-4415-94d2-d24f4d2d9cf4", "ada23e72-1c0f-4d38-a09f-14693e90aeb9"], "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0": {"node_ids": ["2de8a8ae-2cf2-4517-b676-7ad597fa45d2", "5e0d7472-f62f-406b-b43f-faa42fc4683b", "80d80fec-a578-4e90-99e2-8bfcc85ec207", "3140db75-6905-4826-a178-da5318de796e"], "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "1b81acaa-761e-44c7-92ec-2cbe8675743b": {"node_ids": ["7e80259e-3cc1-4133-b552-80263eec164a", "b5dd3fe9-6ada-4e1b-b168-0a8bc36d47a8", "19058b0e-1e94-4a99-9eae-c8f8f07dce83"], "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "40ee037e-52af-4da7-b433-f00011acab8d": {"node_ids": ["979d53bd-b996-4067-9c75-2d6311d1cc52", "831dec67-ed67-41d7-aa5d-28199b50d00a", "e2667920-a83d-457e-8c7b-74d65e73358e"], "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "234c40b0-589f-4ecd-a685-da31379e778e": {"node_ids": ["e9c19ca0-dbb0-4608-8628-3beb7e822fd8", "3891e37a-b49d-43ec-8529-c4b23f6ded5d", "6d645c9e-e77e-4ccd-be3a-3b5fec5f0cbc", "602c45a8-34ed-4c9d-8360-e061daaded0f"], "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "6cb9cdaa-67ea-450a-b4af-b07280e51abf": {"node_ids": ["946056b5-0b10-4bf3-a8de-607f5faedfa8", "46233c45-41ff-42ba-b24c-255ec301b738", "542022e0-535a-4367-8845-affcda1d2f63"], "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "a949a7f4-9c12-4e4c-b600-fc69affde3ce": {"node_ids": ["dd0a4a21-7a9b-4ea5-88b0-d927294f8827", "0186f0a7-3712-449c-9d45-85e479b42831"], "metadata": {"page_label": "17", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "b8f45ef9-0e05-4a12-add2-f9a866a51c97": {"node_ids": ["c48bf46e-d1c3-42b0-bd70-71009c65d1e1", "564c86aa-edfb-4a58-91f3-231d689f482c"], "metadata": {"page_label": "18", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "ed6723b5-7a1c-459f-b8a9-a02444c254c0": {"node_ids": ["7c7caf75-486d-4906-a929-7dce5813c76c"], "metadata": {"page_label": "19", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "d170cc4a-480f-419d-9376-e0a822fc7458": {"node_ids": ["c7b9e4eb-a344-4de6-92ee-f7728e64223e", "bce3975b-dd9a-4456-8b4c-834c86790df9", "6c7ae6ed-40f5-4a0c-a7ef-2c50dc2f5414", "e36c5740-185a-4baf-bf72-2c5e15581d80"], "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "fccb58ca-7e57-49dd-989b-831eed15e271": {"node_ids": ["a2944bdd-1ba4-40eb-9fc9-cef6a660039b", "cf89f48b-46ab-4a30-aad0-e77d4b8fe471", "97de8706-944d-4adb-b275-4f8a65a7eb4e", "1af9fa12-5185-4c5c-b872-90331da112b1"], "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "cc432e08-65eb-41f6-9d68-9b24109c05a9": {"node_ids": ["47934842-e923-436f-98aa-5c890314a2c2", "f08ab8f4-6f73-4106-be4b-f39ee7804501"], "metadata": {"page_label": "22", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "cc17eec2-f6a5-4b74-af6a-6e4f184413fe": {"node_ids": ["46bac1e0-24f2-47b7-bcc4-2658e48bb970", "8d4f9b2b-18bc-488c-bd53-74d4298adf19"], "metadata": {"page_label": "23", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "3ce66208-b3c9-4911-9373-8a7d8db74d6b": {"node_ids": ["db72b9e5-8186-4e5f-ad4b-89526c81d05a"], "metadata": {"page_label": "24", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}, "32d99d0a-a883-4932-bd68-796626301497": {"node_ids": ["6228812a-e038-4e41-8a4c-c577a413d771"], "metadata": {"page_label": "25", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}}}, "docstore/data": {"f6362649-cbf2-4cbe-ba03-7229ff831607": {"__data__": {"id_": "f6362649-cbf2-4cbe-ba03-7229ff831607", "embedding": null, "metadata": {"page_label": "1", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cebe85fe-ba79-4b67-822d-add7854f3662", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "09cf86244e6885d8cc757a47aac106da79e91141188080b3892ef89678131fea", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "014040ad-8955-42b6-afc8-c69c6f43911c", "node_type": "1", "metadata": {}, "hash": "a341a8e904c0863b3bf03ea47fd094379d2d5fe01eb9bf5a633eb04f99b172b5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2025-03-12\nGemma 3 Technical Report\nGemma Team, Google DeepMind1\nWe introduce Gemma 3, a multimodal addition to the Gemma family of lightweight open models, ranging\nin scale from 1 to 27 billion parameters. This version introduces vision understanding abilities, a wider\ncoverage of languages and longer context \u2013 at least 128K tokens. We also change the architecture of\nthe model to reduce the KV-cache memory that tends to explode with long context. This is achieved by\nincreasing the ratio of local to global attention layers, and keeping the span on local attention short.\nThe Gemma 3 models are trained with distillation and achieve superior performance to Gemma 2\nfor both pre-trained and instruction finetuned versions. In particular, our novel post-training recipe\nsignificantly improves the math, chat, instruction-following and multilingual abilities, making Gemma3-\n4B-IT competitive with Gemma2-27B-IT and Gemma3-27B-IT comparable to Gemini-1.5-Pro across\nbenchmarks. We release all our models to the community.\n1. Introduction\nWe present the newest version of Gemma open\nlanguage models (Gemma Team, 2024a), co-\ndesigned with the family of Gemini frontier mod-\nels (Gemini Team, 2023). This new version\ncomes in sizes comparable to Gemma 2 (Gemma\nTeam, 2024b), with the addition of a 1B model.\nThese models are designed to run on standard\nconsumer-grade hardware such as phones, lap-\ntops, and high-end GPUs. This version comes\nwith several new abilities to the Gemma family;\nnamely, multimodality, long context, and mul-\ntilinguality, while preserving or surpassing the\nperformance of prior versions.\nIn terms of multimodality, most Gemma 3 mod-\nels are compatible with a tailored version of the\nSigLIP vision encoder (Zhai et al., 2023). The\nlanguage models treat images as a sequence of\nsoft tokens encoded by SigLIP. We reduce the in-\nference cost of image processing by condensing\nthe vision embeddings into a fixed size of 256\nvectors.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1954, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "014040ad-8955-42b6-afc8-c69c6f43911c": {"__data__": {"id_": "014040ad-8955-42b6-afc8-c69c6f43911c", "embedding": null, "metadata": {"page_label": "1", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cebe85fe-ba79-4b67-822d-add7854f3662", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "09cf86244e6885d8cc757a47aac106da79e91141188080b3892ef89678131fea", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f6362649-cbf2-4cbe-ba03-7229ff831607", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "196a41719e9cb0f289c4d8cf706db3de847009b6f977b2892352b3312c5d2d6d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The encoder works at a fixed resolution\nand we take inspiration from LLaVA (Liu et al.,\n2024) to enable flexible resolutions with a Pan\nand Scan (P&S) method.\nThe second main architectural improvement is\nan increase in context size to 128K tokens, with-\nout reducing performance. A challenge with long\ncontext is the memory explosion of the KV cache\nduring inference. To reduce this issue, we inter-\nleave multiple local layers between each global\nlayer, and assign a smaller span of only 1024\ntokens to the local layers. Therefore, only the\nglobal layers attend to long context, and we have\n1 global for every 5 local layers.\nThe pre-training optimization recipe is similar\nto Gemma 2, with some modifications in the ar-\nchitecture design. We use the same tokenizer as\nGemini 2.0, and we also revisit our data mixture\nto improve the multilingual capabilities of the\nmodels, while introducing image understanding.\nAll Gemma 3 models are trained with knowledge\ndistillation (Hinton et al., 2015).\nIn post-training, we focus our efforts on im-\nproving mathematics, reasoning, and chat abili-\nties, as well as integrating the new capabilities of\nGemma 3, long-context, and image inputs. We\nuse a novel post-training approach that brings\ngains across all capabilities, including math, cod-\ning, chat, instruction following, and multilingual.\nThe resulting Gemma 3 instruction-tuned models\nare both powerful and versatile, outperforming\ntheir predecessors by a wide margin.\nIn the following sections, we provide a brief\noverview of our models, including the architec-\nture and pre- and post-training recipes. We also\nprovide detailed evaluations across a wide vari-\nety of quantitative and qualitative benchmarks.\nWe discuss our approach to safe and responsible\ndeployment and outline the broader implications\nof Gemma 3, its limitations, and advantages.\n1See Contributions and Acknowledgments section for full author list. Please send correspondence togemma-3-report@google.com.\n\u00a9 2025 Google DeepMind. All rights reserved\narXiv:2503.19786v1  [cs.CL]  25 Mar 2025", "mimetype": "text/plain", "start_char_idx": 1955, "end_char_idx": 4014, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7db1ce10-c1aa-4c40-81eb-2a3c191205c3": {"__data__": {"id_": "7db1ce10-c1aa-4c40-81eb-2a3c191205c3", "embedding": null, "metadata": {"page_label": "2", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c156761d-6d08-4b17-b5f8-8ac6b6de0276", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "81fb82252c96d4ad5abddb713e2d2fd5ef6e49a7b91781c08bcc9d16e8064533", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d95d335d-6b34-4b88-9485-94a259d7824f", "node_type": "1", "metadata": {}, "hash": "efaac759f6b80b13e7ee7f7769055d481f50536cbd1e22677e63d25e2c4fb536", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nFigure 1 |Example of visual interaction with\nGemma 3 27B IT model.\n2. Model Architecture\nGemma 3 models follow the same general\ndecoder-only transformer architecture as previ-\nous iterations (Vaswani et al., 2017), with most\narchitecture elements similar to the first two\nGemma versions. We use a Grouped-Query Atten-\ntion (GQA) (Ainslie et al., 2023) with post-norm\nand pre-norm with RMSNorm (Zhang and Sen-\nnrich, 2019). Inspired by Dehghani et al. (2023),\nWortsman et al. (2023) and Chameleon Team\n(2024), we replace the soft-capping of Gemma 2\nwith QK-norm. In this section, we focus on some\nkey differences from previous versions below.\n5:1 interleaving of local/global layers. We\nalternate between a local sliding window self-\nattention (Beltagy et al., 2020) and global self-\nModel Vision\nEncoder\nEmbedding\nParameters\nNon-embedding\nParameters\n1B 0 302M 698M\n4B 417M 675M 3,209M\n12B 417M 1,012M 10,759M\n27B 417M 1,416M 25,600M\nTable 1|Parameter counts for the Gemma 3 mod-\nels. Our vocabulary has 256k entries.\nattention (Luong et al., 2015), with a pattern of\n5 local layers for every global layer, starting with\na local layer as the first layer of the model.\nLong context.Gemma 3 models support context\nlength of 128K tokens, with the exception of the\n1B model that has 32K. We increase RoPE base\nfrequency from 10k to 1M on global self-attention\nlayers, and keep the frequency of the local lay-\ners at 10k. We follow a process similar to the\npositional interpolation of Chen et al. (2023) to\nextend the span of the global self-attention layers.\n2.1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1583, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d95d335d-6b34-4b88-9485-94a259d7824f": {"__data__": {"id_": "d95d335d-6b34-4b88-9485-94a259d7824f", "embedding": null, "metadata": {"page_label": "2", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c156761d-6d08-4b17-b5f8-8ac6b6de0276", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "81fb82252c96d4ad5abddb713e2d2fd5ef6e49a7b91781c08bcc9d16e8064533", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7db1ce10-c1aa-4c40-81eb-2a3c191205c3", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "ea4acb9c9c2648c02c381164fdb0beca1e15f4e3cc8e6df23364fbf3d20e5a2c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2.1. Vision modality\nVision encoder.We use a 400M variant of the\nSigLIP encoder (Zhai et al., 2023), a Vision Trans-\nformer (Dosovitskiy, 2020) trained with a varia-\ntion of the CLIP loss (Radford et al., 2021). The\nGemma vision encoder takes as input square im-\nages resized to 896 x 896, and is finetuned on\ndata fromvisualassistanttasks. Forsimplicity, we\nshare the vision encoder across our 4B, 12B, and\n27B models, keeping it frozen during training.\nPan & Scan (P&S).The Gemma vision encoder\noperates at a fixed resolution of 896\u00d7896. This\nresults in artifacts when processing non-square\naspect ratios and high-resolution images, leading\nto unreadable text, or small objects disappearing.\nWeaddressthisissuewithanadaptivewindowing\nalgorithm during inference. This algorithm seg-\nments images into non-overlapping crops of equal\nsize, covering the whole image, and resize them\nto 896\u00d7896 pixels to pass them to the encoder.\nThis windowing is applied only when necessary,\nand control for the maximum number of crops.\nIt is an inference-time only optimization and can\nbe disabled for faster inference.\n2", "mimetype": "text/plain", "start_char_idx": 1579, "end_char_idx": 2684, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "72464c0d-fe36-42b7-8899-75c35c07db57": {"__data__": {"id_": "72464c0d-fe36-42b7-8899-75c35c07db57", "embedding": null, "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "27921654-c1dc-4312-be04-6ae4d4194c21", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7b1e9830fcd97637d5e7db52cf3c7486c59186f04c1102a70a0e4718da8b88d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e872be7-e989-4e10-ad12-d367dddf2b0f", "node_type": "1", "metadata": {}, "hash": "0989b4ee8bd0d470426b6e707a5885f9195d39c8cdaee52d2c222f8695851841", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nShards\nModel Type #Chips Data Seq. Replica\n1B TPUv5e 512 16 16 2\n4B TPUv5e 2048 16 16 8\n12B TPUv4 6144 16 16 24\n27B TPUv5p 6144 24 8 32\nTable 2|Training infrastructure with sharding by\ndata, sequence (Seq.), and replica.\n2.2. Pre-training\nWe follow a similar recipe as in Gemma 2 for\npre-training with knowledge distillation.\nTraining data. We pre-train our models on a\nslightly larger token budget than Gemma 2, i.e.,\nwe train on 14T tokens for Gemma 3 27B, 12T\nfor the 12B version, 4T for the 4B, and 2T to-\nkens for the 1B. The increase in tokens accounts\nfor the mix of images and text used during pre-\ntraining. We also increase the amount of multi-\nlingual data to improve language coverage. We\nadd both monolingual and parallel data, and we\nhandle the imbalance in language representation\nusing a strategy inspired by Chung et al. (2023).\nTokenizer.We use the same tokenizer as Gem-\nini 2.0: a SentencePiece tokenizer with split dig-\nits, preserved whitespace, and byte-level encod-\nings (Kudo and Richardson, 2018). The resulting\nvocabulary has 262k entries. This tokenizer is\nmore balanced for non-English languages.\nFiltering. We use filtering techniques that reduce\nthe risk of unwanted or unsafe utterances and\nremove certain personal information and other\nsensitive data. We decontaminate evaluation sets\nfrom our pre-training data mixture, and reduce\nthe risk of recitation by minimizing the prolifer-\nation of sensitive outputs. We also apply a qual-\nity reweighing step inspired by Sachdeva et al.\n(2024) to reduce occurrences of low quality data.\nDistillation. We sample 256 logits per token,\nweighted by teacher probabilities.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1669, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e872be7-e989-4e10-ad12-d367dddf2b0f": {"__data__": {"id_": "7e872be7-e989-4e10-ad12-d367dddf2b0f", "embedding": null, "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "27921654-c1dc-4312-be04-6ae4d4194c21", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7b1e9830fcd97637d5e7db52cf3c7486c59186f04c1102a70a0e4718da8b88d7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "72464c0d-fe36-42b7-8899-75c35c07db57", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "59a209981afe880df5a4b3ba58f2fb6fb9d02800c712da1b3c12ee9a920e4fd4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5a27f4bc-4aff-4ddf-bd4c-e575d3b28aa4", "node_type": "1", "metadata": {}, "hash": "74fac808e9bd2fd3f605bccd3727882a856d31ada46c589387df843c55e66157", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The student\nlearns the teacher\u2019s distribution within these sam-\nples via cross-entropy loss. The teacher\u2019s target\ndistribution is set to zero probability for non-\nsampled logits, and renormalized.\nRaw (GB) Quantized (GB)\nModel bf16 Int4 Int4 blocks=32 SFP8\n1B 2.0 0.5 0.7 1.0\n+KV 2.9 1.4 1.6 1.9\n4B 8.0 2.6 2.9 4.4\n+KV 12.7 7.3 7.6 9.1\n12B 24.0 6.6 7.1 12.4\n+KV 38.9 21.5 22.0 27.3\n27B 54.0 14.1 15.3 27.4\n+KV 72.7 32.8 34.0 46.1\nTable 3|Memory footprints (in GB) comparison\nbetween raw (bfloat16) and quantized check-\npoints for weights and KV caching (+KV) at\n32,768 context size, quantized in 8 bits.\n2.3. Quantization Aware Training\nAlong with the raw checkpoints, we also provide\nquantizedversionsofourmodelsindifferentstan-\ndard formats. These versions are obtained by fine-\ntuning each model for a small number of steps,\ntypically 5,000, using Quantization Aware Train-\ning (QAT) (Jacob et al., 2018). We use prob-\nabilities from the non-quantized checkpoint as\ntargets, and adapt the data to match the pre-\ntraining and post-training distributions. Based\non the most popular open source quantization\ninference engines (e.g. llama.cpp), we focus on\nthree weight representations: per-channel int4,\nper-block int4, and switched fp8. In Table 3, we\nreport the memory filled by raw and quantized\nmodels for each weight representation with and\nwithout a KV-cache for a sequence of 32k tokens.\n2.4.", "mimetype": "text/plain", "start_char_idx": 1670, "end_char_idx": 3069, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5a27f4bc-4aff-4ddf-bd4c-e575d3b28aa4": {"__data__": {"id_": "5a27f4bc-4aff-4ddf-bd4c-e575d3b28aa4", "embedding": null, "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "27921654-c1dc-4312-be04-6ae4d4194c21", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7b1e9830fcd97637d5e7db52cf3c7486c59186f04c1102a70a0e4718da8b88d7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e872be7-e989-4e10-ad12-d367dddf2b0f", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "f0d59a25494eafe06da139058472b847712912e917a80a3de128119b81fc04a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2.4. Compute Infrastructure\nWe train our models with TPUv4, TPUv5e, and\nTPUv5p as outlined in Table 2. Each model con-\nfiguration is optimized to minimize training step\ntime. For the vision encoder, we pre-compute\nthe embeddings for each image and directly train\nwith the embeddings, adding no cost to the train-\ning of the language models.\nThe optimizer state is sharded using an im-\nplementation of ZeRO-3 (Ren et al., 2021). For\nmulti-pod training, we perform a data replica re-\n3", "mimetype": "text/plain", "start_char_idx": 3065, "end_char_idx": 3548, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "67c39bfd-203e-4b3e-b6f1-9df456f647e1": {"__data__": {"id_": "67c39bfd-203e-4b3e-b6f1-9df456f647e1", "embedding": null, "metadata": {"page_label": "4", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7f52e7ab-d4e2-4966-aa0d-c7514faecdb9", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "594689f745ebdfb9cc49e17f1d601059ae265f2d86662c054101488564d4f75d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "70d0bc64-5709-4f15-a3f6-328c702f3ebc", "node_type": "1", "metadata": {}, "hash": "db229766960245447e2a30790bd82acb0d305e2623ba8a522640f03df2f07175", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nContext Formatting\nUser turn <start_of_turn>user\nModel turn <start_of_turn>model\nEnd of turn <end_of_turn>\nExample of discussion:\nUser: Who are you?\nModel: My name is Gemma!\nUser: What is 2+2?\nModel: 2+2=4.\nModel input:\n[BOS]<start_of_turn>user\nWho are you?<end_of_turn>\n<start_of_turn>model\nMy name is Gemma!<end_of_turn>\n<start_of_turn>user\nWhat is 2+2?<end_of_turn>\n<start_of_turn>model\nModel output:\n2+2=4.<end_of_turn>\nTable4 |FormattingforGemmaITmodels. Explic-\nitly add the[BOS] token after tokenization, or\nuse theadd_bos=True option in the tokenizer.\nDo not tokenize the text \"[BOS]\".\nduction over the data center network, using the\nPathways approach of Barham et al. (2022). We\nuse the \u2018single controller\u2019 programming paradigm\nof Jax (Roberts et al., 2023) and Pathways\n(Barham et al., 2022), along with the GSPMD\npartitioner (Xu et al., 2021) and the MegaScale\nXLA compiler (XLA, 2019).\n3. Instruction-Tuning\nPre-trained models are turned into instruction-\ntuned models with an improved post-training ap-\nproachcomparedtoourpriorrecipe(seeTable6).\nTechniques. Our post-training approach relies\non an improved version of knowledge distilla-\ntion (Agarwal et al., 2024; Anil et al., 2018; Hin-\nton et al., 2015) from a large IT teacher, along\nwithaRLfinetuningphasebasedonimprovedver-\nsions of BOND (Sessa et al., 2024), WARM (Ram\u00e9\net al., 2024b), and WARP (Ram\u00e9 et al., 2024a).\nReinforcement learning objectives. We use\na variety of reward functions to improve help-\nfulness, math, coding, reasoning, instruction-\nfollowing, and multilingual abilities, while mini-\nmizing model harmfulness.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1625, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "70d0bc64-5709-4f15-a3f6-328c702f3ebc": {"__data__": {"id_": "70d0bc64-5709-4f15-a3f6-328c702f3ebc", "embedding": null, "metadata": {"page_label": "4", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7f52e7ab-d4e2-4966-aa0d-c7514faecdb9", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "594689f745ebdfb9cc49e17f1d601059ae265f2d86662c054101488564d4f75d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67c39bfd-203e-4b3e-b6f1-9df456f647e1", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "74fc3a51497eb903fde231693ed38191c2e0fbeb707bb8c7f079796784b9b8f6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This includes learn-\ning from weight averaged reward models (Ram\u00e9\net al., 2024b) trained with human feedback data,\ncode execution feedback (Gehring et al., 2024),\nand ground-truth rewards for solving math prob-\nlems (DeepSeek-AI, 2025; Lambert et al., 2024).\nData filtering. We carefully optimize the data\nused in post-training to maximize model perfor-\nmance. We filter examples that show certain per-\nsonal information, unsafe or toxic model outputs,\nmistaken self-identification data, and duplicated\nexamples. Including subsets of data that encour-\nage better in-context attribution, hedging, and\nrefusals to minimize hallucinations also improves\nperformance on factuality metrics, without de-\ngrading model performance on other metrics.\n[BOS] token.For both PT and IT models, text\nstartswitha [BOS] token, thatneedstobeadded\nexplicitly since the text \u201c[BOS]\u201d does not map to\nthe[BOS] token. Forinstance,Flaxhasanoption,\nadd_bos=True, to add this token automatically\nwhen tokenizing. An example of the formatting\nfor an IT model is shown in Table 4,\nPT versus IT Formatting.All models share the\nsame tokenizer, with some control tokens dedi-\ncated to IT formatting. A key difference is that PT\nmodels output a<eos> token at the end of gener-\nation, while IT models output a<end_of_turn>\nat the end of the generation, as shown for IT in\nTable 4. Fine-tuning either model type thus also\nrequires adding their respective end tokens.\n4. Evaluation of final models\nIn this section, we evaluate the IT models over\na series of automated benchmarks and human\nevaluations across a variety of domains, as well\nas static benchmarks such as MMLU.\n4.1. LMSYS Chatbot Arena\nIn this section, we report the performance of our\nIT 27B model on LMSys Chatbot Arena (Chiang\net al., 2024) in blind side-by-side evaluations by\nhuman raters against other state-of-the-art mod-\nels. WereportEloscoresinTable5. Gemma327B\n4", "mimetype": "text/plain", "start_char_idx": 1626, "end_char_idx": 3526, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ba321d5-9acb-4d76-b38a-d235a32fdb5c": {"__data__": {"id_": "9ba321d5-9acb-4d76-b38a-d235a32fdb5c", "embedding": null, "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abc0300-2d8b-4b09-9df1-5e65fae7031d", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "290169516ff3feb7a8970ada27e1fc39be9a423584531832253dbc01ce682be5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "325ed854-9ad8-4022-a0c7-252b93486ae2", "node_type": "1", "metadata": {}, "hash": "162239a956d39440ae45f15f7121a02a7b07e1665d19160412017666bcae3be5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nRank Model Elo 95% CI Open Type #params/#activated\n1 Grok-3-Preview-02-24 1412 +8/-10 - - -\n1 GPT-4.5-Preview 1411 +11/-11 - - -\n3 Gemini-2.0-Flash-Thinking-Exp-01-21 1384 +6/-5 - - -\n3 Gemini-2.0-Pro-Exp-02-05 1380 +5/-6 - - -\n3 ChatGPT-4o-latest (2025-01-29) 1377 +5/-4 - - -\n6 DeepSeek-R1 1363 +8/-6 yes MoE 671B/37B\n6 Gemini-2.0-Flash-001 1357 +6/-5 - - -\n8 o1-2024-12-17 1352 +4/-6 - - -\n9 Gemma-3-27B-IT 1338 +8/-9 yes Dense 27B\n9 Qwen2.5-Max 1336 +7/-5 - - -\n9 o1-preview 1335 +4/-3 - - -\n9 o3-mini-high 1329 +8/-6 - - -\n13 DeepSeek-V3 1318 +8/-6 yes MoE 671B/37B\n14 GLM-4-Plus-0111 1311 +8/-8 - - -\n14 Qwen-Plus-0125 1310 +7/-5 - - -\n14 Claude 3.7 Sonnet 1309 +9/-11 - - -\n14 Gemini-2.0-Flash-Lite 1308 +5/-5 - - -\n18 Step-2-16K-Exp 1305 +7/-6 - - -\n18 o3-mini 1304 +5/-4 - - -\n18 o1-mini 1304 +4/-3 - - -\n18 Gemini-1.5-Pro-002 1302 +3/-3 - - -\n...\n28 Meta-Llama-3.1-405B-Instruct-bf16 1269 +4/-3 yes Dense 405B\n...\n38 Llama-3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 960, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "325ed854-9ad8-4022-a0c7-252b93486ae2": {"__data__": {"id_": "325ed854-9ad8-4022-a0c7-252b93486ae2", "embedding": null, "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abc0300-2d8b-4b09-9df1-5e65fae7031d", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "290169516ff3feb7a8970ada27e1fc39be9a423584531832253dbc01ce682be5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ba321d5-9acb-4d76-b38a-d235a32fdb5c", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "2415ca8b25e2262ae359aca6e6d1927e3fb6781358f190db254dbdd27508b2de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "caafb3d4-a155-469f-b40f-ddc38ed38242", "node_type": "1", "metadata": {}, "hash": "e5064610f52c47740b454ee4d2a203cd4babbd10581680291f321c699b36f7f5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "..\n38 Llama-3.3-70B-Instruct 1257 +5/-3 yes Dense 70B\n...\n39 Qwen2.5-72B-Instruct 1257 +3/-3 yes Dense 72B\n...\n59 Gemma-2-27B-it 1220 +3/-2 yes Dense 27B\nTable 5|Evaluation of Gemma 3 27B IT model in the Chatbot Arena (Chiang et al., 2024). All the\nmodels are evaluated against each other through blind side-by-side evaluations by human raters. Each\nmodel is attributed a score, based on the Elo rating system.Gemma-3-27B-IT numbers are preliminary\nresults received on March 8, 2025.\nIT (1338) is among the top 10 best models, with a\nscoreaboveothernon-thinkingopenmodels,such\nas DeepSeek-V3 (1318), LLaMA 3 405B (1257),\nand Qwen2.5-70B (1257), which are much larger\nmodels. Finally, the Elo of Gemma 3 is signifi-\ncantly higher than Gemma 2, at 1220. Note that\nElo scoresdo nottake into account visual abilities,\nwhich none of the aforementioned models have.\n4.2. Standard benchmarks\nIn Table 6, we show the performance of our final\nmodels across a variety of benchmarks compared\nto our previous model iteration, and Gemini 1.5.\nWe do not compare directly with external models\nthat often report their own evaluation settings,\nsincerunningtheminoursettingdoesnotguaran-\nteeafaircomparison. Weencouragethereaderto\nfollow third-party static leaderboards for a fairer\ncomparison across models. We include additional\nevaluations of our models on other benchmarks\nin the appendix.\n5. Ablations\nIn this section, we focus on the impact of our\narchitecturechanges, aswellassomeofthevision\nabilities new to this model.\n5.1.", "mimetype": "text/plain", "start_char_idx": 946, "end_char_idx": 2460, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "caafb3d4-a155-469f-b40f-ddc38ed38242": {"__data__": {"id_": "caafb3d4-a155-469f-b40f-ddc38ed38242", "embedding": null, "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abc0300-2d8b-4b09-9df1-5e65fae7031d", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "290169516ff3feb7a8970ada27e1fc39be9a423584531832253dbc01ce682be5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "325ed854-9ad8-4022-a0c7-252b93486ae2", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "bfd7c25683a268de03ff19c7972fa236b9352133dc346daea74f508bd58a0cd2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5.1. Pre-training ability probing\nWe use several standard benchmarks as probes\nduring pre-training to ensure our models capture\ngeneral abilities, and in Figure 2, we compare the\nquality of pre-trained models from Gemma 2 and\n3 across these general abilities, namely, science,\n5", "mimetype": "text/plain", "start_char_idx": 2456, "end_char_idx": 2734, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "576440ce-d9b2-4152-8215-02be62c9295c": {"__data__": {"id_": "576440ce-d9b2-4152-8215-02be62c9295c", "embedding": null, "metadata": {"page_label": "6", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a78419c4-2b31-4a00-b89b-92b1abc61c1c", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "29e5926bf07ab45185332b24028abbb7f5fca96f470b87a45ef85d615bd9da6b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "33e9f339-0f4e-48ad-b229-44948c014104", "node_type": "1", "metadata": {}, "hash": "afe4653227344e7416ad38066310675ce872cd03cf742797e7c5c3bdfe954682", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nGemini 1.5 Gemini 2.0 Gemma 2 Gemma 3\nFlash Pro Flash Pro 2B 9B 27B 1B 4B 12B 27B\nMMLU-Pro 67.3 75.8 77.6 79.1 15.6 46.8 56.9 14.7 43.6 60.6 67.5\nLiveCodeBench 30.7 34.2 34.5 36.0 1.2 10.8 20.4 1.9 12.6 24.6 29.7\nBird-SQL (dev) 45.6 54.4 58.7 59.3 12.2 33.8 46.7 6.4 36.3 47.9 54.4\nGPQA Diamond 51.0 59.1 60.1 64.7 24.7 28.8 34.3 19.2 30.8 40.9 42.4\nSimpleQA 8.6 24.9 29.9 44.3 2.8 5.3 9.2 2.2 4.0 6.3 10.0\nFACTS Grounding 82.9 80.0 84.6 82.8 43.8 62.0 62.4 36.4 70.1 75.8 74.9\nGlobal MMLU-Lite 73.7 80.8 83.4 86.5 41.9 64.8 68.6 34.2 54.5 69.5 75.1\nMATH 77.9 86.5 90.9 91.8 27.2 49.4 55.6 48.0 75.6 83.8 89.0\nHiddenMath 47.2 52.0 63.5 65.2 1.8 10.4 14.8 15.8 43.0 54.5 60.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 698, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "33e9f339-0f4e-48ad-b229-44948c014104": {"__data__": {"id_": "33e9f339-0f4e-48ad-b229-44948c014104", "embedding": null, "metadata": {"page_label": "6", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a78419c4-2b31-4a00-b89b-92b1abc61c1c", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "29e5926bf07ab45185332b24028abbb7f5fca96f470b87a45ef85d615bd9da6b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "576440ce-d9b2-4152-8215-02be62c9295c", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7425b5b3767a480e8a2da21c3a348947f2968953b201577569347f3aa195d661", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "0 54.5 60.3\nMMMU (val) 62.3 65.9 71.7 72.7 - - - - 48.8 59.6 64.9\nTable 6|Performance of instruction fine-tuned (IT) models compared to Gemini 1.5, Gemini 2.0, and\nGemma 2 on zero-shot benchmarks across different abilities.\nFigure 2|Summary of the performance of different pre-trained models from Gemma 2 and 3 across\ngeneral abilities. These plots are meant to give a simplified summary and details are in the appendix.\ncode, factuality, multilinguality, reasoning, and\nvision. The details of the performance across the\ndifferent public benchmarks used in these plots\nare summarized in the appendix. Overall, we see\nthat the new versions improve in most categories,\ndespite the addition of vision. We particularly\nfocus on multilinguality in this version, and this\ndirectly impacts the quality of our models. How-\never, despite the use of decontamination tech-\nniques, there is always a risk of contamination\nof these probes (Mirzadeh et al., 2024), making\nmore definitive conclusions harder to assess.\n5.2. Local:Global attention layers\nWe measure the impact of changes to local and\nglobal self-attention layers on performance and\nmemory consumption during inference.\nLocal:Global ratio.In Fig. 3, we compare differ-\n1:1 3:1 5:1 7:1\nLocal:Global\n0.1\n0.0\n0.1\n Perplexity\n2B\n9B\nFigure 3|Impact of Local:Global ratioon the\nperplexity on a validation set. The impact is mini-\nmal,evenwith7-to-1localtoglobal. Thisablation\nis run with text-only models.\nent ratios of local to global attention layers. 1:1\nis used in Gemma 2 models, and 5:1 is used in\nGemma 3. We observe minimal impact on per-\nplexity when changing this ratio.\nSliding window size. In Fig. 4, we compare\ndifferent sliding window sizes for the local at-\n6", "mimetype": "text/plain", "start_char_idx": 688, "end_char_idx": 2406, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4c41ca3e-a5a4-473e-9023-4b41970a634a": {"__data__": {"id_": "4c41ca3e-a5a4-473e-9023-4b41970a634a", "embedding": null, "metadata": {"page_label": "7", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d83d8b5f-4061-45d2-a27b-051694a59e76", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "e200dbcb53cf229a693765274d0a4f47cc38fc7bc19316003c56a506b8fc95b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "15a9cd10-9747-4034-b731-67c2d883f805", "node_type": "1", "metadata": {}, "hash": "ac8da119914f5245b8c3d43ec176971422f46a21ace1b2c1efe1c908a645b610", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\ntention layers in different global:local ratio con-\nfigurations. The sliding window can be reduced\nsignificantly without impacting perplexity.\n512 1024 2048 4096\nSliding Window\n0.02\n0.01\n0.00\n0.01\n Perplexity\n2B L:G=1:1\n2B L:G=3:1\nFigure 4|Impact of Sliding Windowsize on per-\nplexity measured on a validation set. We consider\n22Bmodels, with1:1and1:3localtogloballayer\nratios. This ablation is run with text-only models.\nImpact on KV cache memory.In Fig. 5, we show\nthe balance between the memory used by the\nmodel and the KV cache during inference with a\ncontext of 32k tokens. The \u201cglobal only\u201d configu-\nration is the standard configuration used across\nmost dense models. The \u201c1:1, sw=4096\u201d is used\nin Gemma 2. We observe that the \u201cglobal only\u201d\nconfiguration results in a memory overhead of\n60%, while this is reduced to less than 15% with\n1:3 and sliding windows of 1024 (\u201csw=1024\u201d).\nIn Fig. 6, we compute the memory used by the\nKV cache as a function of the context length with\neither our 2B architecture (L:G=5:1, sw=1024)\nversus a \u201cglobal only\u201d 2B model.\nglobal only 1:1, sw=4096 1:1 sw=1024 1:3 sw=4096 1:3 sw=1024\n0\n1000\n2000\n3000\n4000\n5000Inference memory (MB)\nmodel\nkv cache\nFigure 5|Model versus KV cache memorydur-\ning inference with a pre-fill KV cache of size 32k.\nWe consider a 2B model with different local to\nglobal ratios and sliding window sizes (sw). We\ncompare to global only, which is the standard\nused in Gemma 1 and Llama. This ablation is run\nwith a text-only model.\n5.3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1522, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "15a9cd10-9747-4034-b731-67c2d883f805": {"__data__": {"id_": "15a9cd10-9747-4034-b731-67c2d883f805", "embedding": null, "metadata": {"page_label": "7", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d83d8b5f-4061-45d2-a27b-051694a59e76", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "e200dbcb53cf229a693765274d0a4f47cc38fc7bc19316003c56a506b8fc95b9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4c41ca3e-a5a4-473e-9023-4b41970a634a", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "d73fb508107f2c78f61302d46387a500184410e27a0e7ca9c0d16ff0d6efacf8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5.3. Enabling long context\nInstead of training with 128K sequences from\nscratch, we pre-train our models with 32K se-\n1K 4K 8K 16K 32K 64K 128K\nContext length\n0\n2000\n4000\n6000KV Cache memory (MB)\n2B L:G=5:1, sw=1024\n2B global only\nFigure 6 |KV cache memory versus context\nlength. We show the memory usage of the KV\ncache for our architecture (L:G=5:1, sw=1024)\nand a transformer with global attention only \u2013 as\nused in LLaMa or Gemma 1.\nquencesandthenscalethe4B,12B,and27Bmod-\nels up to 128K tokens at the end of pre-training\nwhile rescaling RoPE (Chen et al., 2023). We\nfind a scaling factor of 8 to work well in practice.\nNote that compared to Gemma 2, we have also\nincreased the RoPE base frequency of global self-\nattention layers from 10k to 1M, while keeping\n10k for the local self-attention layers. In Figure 7,\nwe show the impact on perplexity for different\ncontext lengths. Our models generalize to 128K,\nbut rapidly degrade as we continue to scale.\nFigure 7 |Long context performance of pre-\ntrained models before and after RoPE rescaling.\n5.4. Small versus large teacher\nA common finding is that, to train a small model,\nit is preferable to distill from a smaller teacher.\n7", "mimetype": "text/plain", "start_char_idx": 1518, "end_char_idx": 2703, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "aac6013d-e349-416f-95e5-64cd6eaa80e6": {"__data__": {"id_": "aac6013d-e349-416f-95e5-64cd6eaa80e6", "embedding": null, "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8247018b-9463-4da0-9106-b82b91c29fdd", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7ad554c70d685aeeb116d55f13e32ca7f1914a8d8f3c08d796274e043c4c08da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c13636e0-5a27-4e10-9957-ec1131a7b208", "node_type": "1", "metadata": {}, "hash": "fc7e83f66c5ccace847ae688f8dcf678346126b1e691a077543d4fd25cd1f422", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\n101 102\nT otal training tokens (B)\n0.006\n0.004\n0.002\n0.000\n0.002\n Perplexity\nFigure 8|Small versus large teacher.Relative\ndifference of perplexity when using a small and\nlarge teacher as a function of the token size of\ntraining. Smaller numbers means distilling from\na larger teacher is better.\nWe suspect this is because these studies are often\nperformed in settings where the regularization ef-\nfect of using a worse teacher surpasses the benefit\nof using a better teacher. We train a student with\n2 teachers of different sizes, one large and one\nsmall, for different training horizons. In Fig. 8,\nwe observe that for short training horizons, the\nsmaller teacher is better, but the trend is reversed\nfor longer training.\n5.5. Vision encoder\nResolution DocVQA InfoVQA TextVQA\n256 31.9 23.1 44.1\n448 45.4 31.6 53.5\n896 59.8 33.7 58.0\nTable 7|Impact of image encoder input reso-\nlution. We measure performance using a short\nschedule 2B Gemma model on a few evaluation\nbenchmarks to observe the effect of input image\nresolution on vision encoder pre-training.\nImpact of image resolution.We use a vision\nencoder based on SigLIP (Zhai et al., 2023). The\nvision encoder is frozen, and only the language\nmodel is trained. Each image in this multimodal\ndata is represented by 256 image tokens from\nthe respective vision encoder. The higher resolu-\ntion encoders thus use average pooling to reduce\ntheir output to 256 tokens. For instance, the 896\nresolution encoder has a 4x4 average pooling on\nits output. As shown in Table 7, higher resolution\nencoders perform better than smaller ones.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1606, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c13636e0-5a27-4e10-9957-ec1131a7b208": {"__data__": {"id_": "c13636e0-5a27-4e10-9957-ec1131a7b208", "embedding": null, "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8247018b-9463-4da0-9106-b82b91c29fdd", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7ad554c70d685aeeb116d55f13e32ca7f1914a8d8f3c08d796274e043c4c08da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aac6013d-e349-416f-95e5-64cd6eaa80e6", "node_type": "1", "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "c56b3290269e4783e061768aa7341dd0864bec851b98af30dd0e29cfea779eb0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "067d87de-26c6-47f8-99eb-99e2c7255460", "node_type": "1", "metadata": {}, "hash": "f4c4c6283643fb4e3ba329d62262857c00eaf1d943c972f826a3a35380d6d576", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DocVQA InfoVQA TextVQA\n4B 72.8 44.1 58.9\n4B w/ P&S 81.0 57.0 60.8\n\u0394 (+8.2) (+12.9) (+1.9)\n27B 85.6 59.4 68.6\n27B w/ P&S 90.4 76.4 70.2\n\u0394 (+4.8) (+17.0) (+1.6)\nTable 8|Impact of P&S.4-shot evaluation re-\nsults on the valid set, with and without P&S on a\npre-trained checkpoint. Boosts are on tasks asso-\nciated with images with varying aspect ratios, or\ninvolving reading text on images.\nPan & Scan.P&S enables capturing images at\nclose to their native aspect ratio and image reso-\nlution. In Table 8, we compare our 27B IT model\nwith and without P&S. As expected, the ability\nto treat images with close to native resolution\ngreatly helps with tasks that require some form\nof reading text on images, which is particularly\nimportant for visual language models.\n6. Memorization and Privacy\nLarge language models may produce near-copies\nof some text used in training (Biderman et al.,\n2023; Carlini et al., 2021, 2022; Ippolito et al.,\n2022; Nasr et al., 2023). Several prior reports\nhave released audits that quantify this risk by\nmeasuring the memorization rate (Anil et al.,\n2023; Chowdhery et al., 2022; Gemini Team,\n2023, 2024; Gemma Team, 2024a,b; LLaMa\nTeam, 2024). This \u201cmemorization rate\u201d1 is de-\nfined as the ratio of generations from the model\nthatmatchitstrainingdatacomparedtoallmodel\ngenerations using the following setup. We fol-\nlow the methodology described in Gemma Team\n1\"We do not state or imply [here] that a model \"contains\"\nits training data in the sense that there is a copy of that data\nin the model.", "mimetype": "text/plain", "start_char_idx": 1607, "end_char_idx": 3128, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "067d87de-26c6-47f8-99eb-99e2c7255460": {"__data__": {"id_": "067d87de-26c6-47f8-99eb-99e2c7255460", "embedding": null, "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8247018b-9463-4da0-9106-b82b91c29fdd", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7ad554c70d685aeeb116d55f13e32ca7f1914a8d8f3c08d796274e043c4c08da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c13636e0-5a27-4e10-9957-ec1131a7b208", "node_type": "1", "metadata": {"page_label": "8", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "ae94a2ebb964d4631b54af1e24c6abb2a03797876e79482b53352eafbe4d1c4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Rather, a model memorizes attributes of its\ntraining data such that in certain cases it is statistically able\nto generate such training data when following rules and\nusing information about features of its training data that it\ndoes contain.\"\n8", "mimetype": "text/plain", "start_char_idx": 3129, "end_char_idx": 3373, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4a51c20c-d4c0-4a4d-b596-1cb67c1ca20b": {"__data__": {"id_": "4a51c20c-d4c0-4a4d-b596-1cb67c1ca20b", "embedding": null, "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "48d4f33c-dd32-47fe-a421-30610383171d", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9be3ea2a829450677b881c9e8ec588984dca7a18213b442bbb2c77df748c59cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "721baf6a-39ca-49ba-9f89-060af35d177e", "node_type": "1", "metadata": {}, "hash": "dad80a627f800e25194fbe5bf26e70051e602954d8876e332714c98291ee0002", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nGemma 31B Gemma 34B Gemma 312BGemma 327B Gemma 2 2B Gemma 2 9B Gemma 2 27BGemini 1.5Flash\nGemma2B Gemma7B PaLM\nSmall\nModel\n0.0001\n0.001\n0.01\n0.1\n1\n10\n% Memorized\nT otal Memorization Rate\nMemorization T ype\nExact Approximate\nFigure 9|Total memorization rates for both ex-\nact and approximate memorization. Gemma 3\nmodels memorize significantly less than all prior\nmodels. *No results for approximate memoriza-\ntion on these models.\n(2024b) to measure it. Specifically, we subsam-\nple a large portion of training data distributed\nuniformly across different corpora and test for\ndiscoverable extraction (Nasr et al., 2023) of this\ncontent using a prefix of length 50 and a suffix of\nlength 50. We denote text as either \u201cexactly mem-\norized\u201d if all tokens in the continuation match\nthe source suffix or \u201capproximately memorized\u201d\nif they match up to an edit distance of 10%.\nFigure 9 compares the memorization rates\nacross Gemma and Gemini models; these models\nare ordered in reverse chronological order, with\nthe newest Gemma 3 models on the left. We find\nthat Gemma 3 models memorize long-form text\nat a much lower rate than prior models (note the\nlog y-axis). We observe only a marginal differ-\nence in the memorization rates between the 4B,\n12B, and 27B models, with 1B memorizing less\nthan these larger models. Further, we find that a\nlarger proportion of text is characterized as ap-\nproximately memorized, with a relative increase\nin approximate memorization compared to exact\nmemorization of roughly 24x on average.\nWe also study the rate at which the generations\nmay contain personal information.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1625, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "721baf6a-39ca-49ba-9f89-060af35d177e": {"__data__": {"id_": "721baf6a-39ca-49ba-9f89-060af35d177e", "embedding": null, "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "48d4f33c-dd32-47fe-a421-30610383171d", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9be3ea2a829450677b881c9e8ec588984dca7a18213b442bbb2c77df748c59cb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a51c20c-d4c0-4a4d-b596-1cb67c1ca20b", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7ec2e1fa4262a50947efe4d50bf901137344d6ccc11f182db445f6f492afc019", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e13a176-2568-4dd0-a36c-a1f66c2c4510", "node_type": "1", "metadata": {}, "hash": "a9d60180af7054a2dacf8103ab599e47e0dd931f842f9a3dc38d32e7231943e2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To identify po-\ntentially personal information, we use the Google\nCloud Sensitive Data Protection (SDP) service.2\nSDP uses broad detection rules to identify text\nthat may contain personal information. SDP is\n2https://cloud.google.com/sensitive-data-protection\ndesigned to have high recall and does not con-\nsider the context in which the information may\nappear, which leads to many false positives. Thus,\nwe are likely overestimating the true amount of\npotentially personal information contained in the\noutputs classified as memorized. SDP also pro-\nvides broad severity levels: low, medium, and\nhigh. We classify text as personal if SDP clas-\nsifies it as personal information at any severity\nlevel. We observed no personal information in\nthe outputs characterized as memorization for all\nGemma 3 models. This indicates a low rate of\npersonal data, below our detection thresholds, in\noutputs classified as memorization.\n7. Responsibility, Safety, Security\nResponsibility, safety, and security are of utmost\nimportance in the development of Gemma mod-\nels. To reduce risks to Gemma 3 users, we have\ncontinued to integrate enhanced internal safety\nprocesses that span the development workflow,\nin line with recent Google AI models (Gemini\nTeam, 2024). This focuses on safety mitigation at\ntraining time, and robust and transparent model\nevaluations for the new image-to-text capabilities\nwe have introduced.\n7.1. Governance & Assessment\nOur approach to assessing the benefits and risks\nofGemmaisreflectiveofthatoutlinedforGemma\n1 (Gemma Team, 2024a), taking into account the\nchanges in supported modalities. We continue to\nbelieve that openness in AI can spread the bene-\nfits of these technologies across society, but must\nbe evaluated against the risk of malicious uses\nthat can cause harm on both individual and in-\nstitutional levels (Weidinger et al., 2021).", "mimetype": "text/plain", "start_char_idx": 1626, "end_char_idx": 3488, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e13a176-2568-4dd0-a36c-a1f66c2c4510": {"__data__": {"id_": "7e13a176-2568-4dd0-a36c-a1f66c2c4510", "embedding": null, "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "48d4f33c-dd32-47fe-a421-30610383171d", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9be3ea2a829450677b881c9e8ec588984dca7a18213b442bbb2c77df748c59cb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "721baf6a-39ca-49ba-9f89-060af35d177e", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9c1347f7749164b0e4f88f819c0ec3cca80c3a07da9ed150bdd8289adb996326", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since\nthe inaugural Gemma launch, we have seen these\nmodels drive a number of socially beneficial ap-\nplications, such as our own ShieldGemma 2, a 4B\nimage safety classifier built with Gemma 3, which\nprovides a ready-made solution for image safety,\noutputtingsafetylabelsacrossdangerouscontent,\nsexually explicit, and violence categories.\nReleasing Gemma 3 models required specific\nattention to changes in model capabilities and\n9", "mimetype": "text/plain", "start_char_idx": 3489, "end_char_idx": 3919, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "17a21ccf-d2e1-4871-b4c5-8e4469a9daaf": {"__data__": {"id_": "17a21ccf-d2e1-4871-b4c5-8e4469a9daaf", "embedding": null, "metadata": {"page_label": "10", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0f6bf0c-0fec-4c71-a5e3-4157e1c0e377", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "1efafc7a29a46748500af9d72fb3fa61fea5228a5f821a54a6a697f4e392efb3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "61a1b29f-ec49-4fc7-a321-83037fe8f747", "node_type": "1", "metadata": {}, "hash": "d2eebe87d7f5943804d346d1870cee34daed210422f87e41902b813b901b35b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nclose monitoring of the evolving risks of existing\nmultimodal LLMs (Lin et al., 2024), as well as an\nunderstanding of the ways in which models are\nbeing used in the wild. Although we are yet to\nreceive any reports of malicious use for Gemma,\nwe remain committed to investigating any such\nreporting, and work with the academic and de-\nveloper communities, as well as conduct our own\nmonitoring, to flag such cases.\nDespite advancements in capabilities, we be-\nlieve that, given the number of larger powerful\nopen models available, this release will have a\nnegligible effect on the overall risk landscape.\n7.2. Safety policies and train-time mitigations\nA key pillar of Gemma\u2019s approach to safety is to\nalign fine-tuned models with Google\u2019s safety poli-\ncies, in line with Gemini models (Gemini Team,\n2023). They are designed to help prevent our\nmodels from generating harmful content, i.e.,\n\u2022 Child sexual abuse and exploitation\n\u2022 Revealingpersonallyidentifiableinformation\nthat can lead to harm (e.g., Social Security\nnumbers)\n\u2022 Hate speech and harassment\n\u2022 Dangerous or malicious content (including\npromoting self-harm or instructing in harm-\nful activities)\n\u2022 Sexually explicit content\n\u2022 Medicaladvicethatrunscontrarytoscientific\nor medical consensus\nWe undertook considerable safety filtering of our\npre-training data to reduce the likelihood of our\npre-trainedandfine-tunedcheckpointsproducing\nharmful content. For fine-tuned models, we also\nuse both SFT and RLHF to steer the model away\nfrom undesirable behavior.\n7.3. Assurance Evaluations\nWe also run our IT models through a set of base-\nline assurance evaluations to understand the po-\ntential harms that our models can cause. As we\nchampion open models, we also recognize that\nthe irreversible nature of weight releases requires\nrigorous risk assessment. Our internal safety pro-\ncesses are designed accordingly, and for previ-\nous Gemma models we have also undertaken\nevaluations of capabilities relevant to extreme\nrisks (Phuong et al., 2024; Shevlane et al., 2023).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2052, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "61a1b29f-ec49-4fc7-a321-83037fe8f747": {"__data__": {"id_": "61a1b29f-ec49-4fc7-a321-83037fe8f747", "embedding": null, "metadata": {"page_label": "10", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0f6bf0c-0fec-4c71-a5e3-4157e1c0e377", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "1efafc7a29a46748500af9d72fb3fa61fea5228a5f821a54a6a697f4e392efb3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "17a21ccf-d2e1-4871-b4c5-8e4469a9daaf", "node_type": "1", "metadata": {"page_label": "10", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "a82885934a0236120de8ee2e1704dbfa76c5d97bb6a8cbeb660d218bbf29ed4c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "As we continue to develop and share open mod-\nels, we will follow the heuristic that thoroughly\nevaluating a more capable model often provides\nsufficient assurance for less capable ones. As such,\nwe prioritised a streamlined set of evaluations for\nGemma 3, reserving in-depth dangerous capabil-\nity assessments for cases where a specific model\nmay present a potentially heightened risk (as de-\nscribed below on CBRN evaluations). We balance\ndevelopment speed with targeted safety testing,\nensuring our evaluations are well-focused and\nefficient, while upholding the commitments laid\nout in our Frontier Safety Framework.\nBaseline Evaluations\nBaseline assurance captures the model violation\nrate for safety policies, using a large number of\nsynthetic adversarial user queries, and human\nraters to label the answers as policy violating or\nnot. Overall, Gemma 3 violation rate is signifi-\ncantly low overall on these safety policies.\nChemical, Biological, Radiological and Nuclear\n(CBRN) knowledge\nOwing to enhanced performance on STEM-\nrelated tasks, we evaluated knowledge relevant\nto biological, radiological, and nuclear risks using\nan internal dataset of closed-ended, knowledge-\nbased multiple choice questions. For evaluations\nof chemical knowledge, we employed a closed-\nended knowledge-based approach on chemical\nhazards developed by Macknight et al. Our eval-\nuation suggests that the knowledge of Gemma 3\nmodels in these domains is low.\n7.4. Ourapproachtoresponsibleopenmodels\nDesigning safe, secure, and responsible applica-\ntions requires a system-level approach, working\nto mitigate risks associated with each specific use\ncase and environment. We will continue to adopt\nassessments and safety mitigations proportion-\nate to the potential risks from our models, and\n10", "mimetype": "text/plain", "start_char_idx": 2053, "end_char_idx": 3832, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cf4e458f-2ca1-4fd0-8cc9-7243f98a95d5": {"__data__": {"id_": "cf4e458f-2ca1-4fd0-8cc9-7243f98a95d5", "embedding": null, "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7907595d-1b6b-4d8f-b919-31bd87aac258", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "4d4b89e1e97e1a76da599c83295a44b4905b31ceeae9986c00f8a0d7f1100987", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4bf37bb2-484b-4415-94d2-d24f4d2d9cf4", "node_type": "1", "metadata": {}, "hash": "dbd4278f6acb3ca399467995e0d7c6950d31e0912c7e19059e136b571c594c56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nwill only share these with the community when\nwe are confident that the benefits significantly\noutweigh the foreseeable risks.\n8. Discussion and Conclusion\nIn this work, we have presented Gemma 3, the\nlatest addition to the Gemma family of open lan-\nguage models for text, image, and code. In this\nversion, we focus on adding image understanding\nand long context while improving multilinguality\nand STEM-related abilities. Our model sizes and\narchitectures are designed to be compatible with\nstandard hardware, and most of our architecture\nimprovements are tailored to fit this hardware\nwhile maintaining performance.\nReferences\nRealworldqa. https://x.ai/news/grok-1.\n5v.\nM. Acharya, K. Kafle, and C. Kanan. Tallyqa: An-\nswering complex counting questions. InAAAI,\n2018.\nR.Agarwal,N.Vieillard,Y.Zhou,P.Stanczyk,S.R.\nGarea, M. Geist, and O. Bachem. On-policy\ndistillation of language models: Learning from\nself-generated mistakes. InICLR, 2024.\nJ. Ainslie, J. Lee-Thorp, M. de Jong, Y. Zemlyan-\nskiy, F. Lebr\u00f3n, and S. Sanghai. Gqa: Training\ngeneralized multi-query transformer models\nfrom multi-head checkpoints. arXiv preprint\narXiv:2305.13245, 2023.\nR. Anil, G. Pereyra, A. Passos, R. Ormandi, G. E.\nDahl, and G. E. Hinton. Large scale distributed\nneural network training through online distil-\nlation. arXiv preprint arXiv:1804.03235, 2018.\nR. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lep-\nikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey,\nZ. Chen, et al. Palm 2 technical report.arXiv\npreprint arXiv:2305.10403, 2023.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1549, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4bf37bb2-484b-4415-94d2-d24f4d2d9cf4": {"__data__": {"id_": "4bf37bb2-484b-4415-94d2-d24f4d2d9cf4", "embedding": null, "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7907595d-1b6b-4d8f-b919-31bd87aac258", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "4d4b89e1e97e1a76da599c83295a44b4905b31ceeae9986c00f8a0d7f1100987", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cf4e458f-2ca1-4fd0-8cc9-7243f98a95d5", "node_type": "1", "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "bbf2485fde5497e5f13291b4b2e3eb67fd968baf19f2d74f51595e151bba655b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ada23e72-1c0f-4d38-a09f-14693e90aeb9", "node_type": "1", "metadata": {}, "hash": "23383afd85199e5edc974bd931a746444d019697bae59e98dbf0bac9e2a65490", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "M. Artetxe, S. Ruder, and D. Yogatama. On the\ncross-lingualtransferabilityofmonolingualrep-\nresentations. InACL, 2020.\nA. Asai, J. Kasai, J. H. Clark, K. Lee, E. Choi,\nand H. Hajishirzi. Xor qa: Cross-lingual open-\nretrieval question answering. arXiv preprint\narXiv:2010.11856, 2020.\nJ. Austin, A. Odena, M. I. Nye, M. Bosma,\nH. Michalewski, D. Dohan, E. Jiang, C. J. Cai,\nM. Terry, Q. V. Le, and C. Sutton. Program\nsynthesis with large language models.CoRR,\nabs/2108.07732, 2021.\nP. Barham, A. Chowdhery, J. Dean, S. Ghemawat,\nS. Hand, D. Hurt, M. Isard, H. Lim, R. Pang,\nS. Roy, B. Saeta, P. Schuh, R. Sepassi, L. E.\nShafey, C. A. Thekkath, and Y. Wu. Path-\nways: Asynchronous distributed dataflow for\nml, 2022.\nI. Beltagy, M. E. Peters, and A. Cohan. Long-\nformer: The long-document transformer.arXiv\npreprint arXiv:2004.05150, 2020.\nS. Biderman, U. Prashanth, L. Sutawika,\nH. Schoelkopf, Q. Anthony, S. Purohit, and\nE. Raff. Emergent and predictable memoriza-\ntion in large language models.NeurIPS, 36:\n28072\u201328090, 2023.\nY. Bisk, R. Zellers, R. L. Bras, J. Gao, and Y. Choi.\nPIQA: reasoning about physical commonsense\nin natural language.CoRR, abs/1911.11641,\n2019.", "mimetype": "text/plain", "start_char_idx": 1550, "end_char_idx": 2720, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ada23e72-1c0f-4d38-a09f-14693e90aeb9": {"__data__": {"id_": "ada23e72-1c0f-4d38-a09f-14693e90aeb9", "embedding": null, "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7907595d-1b6b-4d8f-b919-31bd87aac258", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "4d4b89e1e97e1a76da599c83295a44b4905b31ceeae9986c00f8a0d7f1100987", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4bf37bb2-484b-4415-94d2-d24f4d2d9cf4", "node_type": "1", "metadata": {"page_label": "11", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "6202af85a9632d177d20dd93cf89b59e25feb5eda023afa74fb5e802cac72f75", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "N. Carlini, F. Tramer, E. Wallace, M. Jagielski,\nA. Herbert-Voss, K. Lee, A. Roberts, T. Brown,\nD. Song, U. Erlingsson, et al. Extracting train-\ning data from large language models. In\nUSENIX, 2021.\nN. Carlini, D. Ippolito, M. Jagielski, K. Lee,\nF. Tramer, and C. Zhang. Quantifying memo-\nrization across neural language models.arXiv\npreprint arXiv:2202.07646, 2022.\nChameleon Team. Chameleon: Mixed-modal\nearly-fusion foundation models.arXiv preprint\narXiv:2405.09818, 2024.\nM. Chen, J. Tworek, H. Jun, Q. Yuan, H. P.\nde Oliveira Pinto, J. Kaplan, H. Edwards,\nY. Burda, N. Joseph, G. Brockman, A. Ray,\nR. Puri, G. Krueger, M. Petrov, H. Khlaaf,\n11", "mimetype": "text/plain", "start_char_idx": 2721, "end_char_idx": 3369, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2de8a8ae-2cf2-4517-b676-7ad597fa45d2": {"__data__": {"id_": "2de8a8ae-2cf2-4517-b676-7ad597fa45d2", "embedding": null, "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "99c30108165f4694fa21dc44e2ee9d75ece6ff6e8e4d7bdfdd02c8490f72699a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e0d7472-f62f-406b-b43f-faa42fc4683b", "node_type": "1", "metadata": {}, "hash": "0be31f5cb4cf42d7871fd8c8a00b5a911adb87be949ff17ed2e63da644256e4c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nG. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ry-\nder, M. Pavlov, A. Power, L. Kaiser, M. Bavar-\nian, C. Winter, P. Tillet, F. P. Such, D. Cum-\nmings, M. Plappert, F. Chantzis, E. Barnes,\nA.Herbert-Voss, W.H.Guss, A.Nichol, A.Paino,\nN. Tezak, J. Tang, I. Babuschkin, S. Balaji,\nS. Jain, W. Saunders, C. Hesse, A. N. Carr,\nJ. Leike, J. Achiam, V. Misra, E. Morikawa,\nA.Radford, M.Knight, M.Brundage, M.Murati,\nK. Mayer, P. Welinder, B. McGrew, D. Amodei,\nS. McCandlish, I. Sutskever, and W. Zaremba.\nEvaluating large language models trained on\ncode. CoRR, abs/2107.03374, 2021.\nS. Chen, S. Wong, L. Chen, and Y. Tian. Extend-\ning context window of large language mod-\nels via positional interpolation.arXiv preprint\narXiv:2306.15595, 2023.\nX.Chen, H.Fang, T.-Y.Lin, R.Vedantam, S.Gupta,\nP. Doll\u00e1r, and C. L. Zitnick. Microsoft coco\ncaptions: Data collection and evaluation server.\nArXiv, abs/1504.00325, 2015.\nW.-L. Chiang, L. Zheng, Y. Sheng, A. N. An-\ngelopoulos, T. Li, D. Li, H. Zhang, B. Zhu,\nM. Jordan, J. E. Gonzalez, and I. Stoica. Chat-\nbot arena: An open platform for evaluating\nllms by human preference, 2024.\nF. Chollet. On the measure of intelligence.arXiv\npreprint arXiv:1911.01547, 2019.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1224, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e0d7472-f62f-406b-b43f-faa42fc4683b": {"__data__": {"id_": "5e0d7472-f62f-406b-b43f-faa42fc4683b", "embedding": null, "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "99c30108165f4694fa21dc44e2ee9d75ece6ff6e8e4d7bdfdd02c8490f72699a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2de8a8ae-2cf2-4517-b676-7ad597fa45d2", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "84246c282e1b45d61f75413cae7327665188c3dac03a1869d2edcf4850e967f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "80d80fec-a578-4e90-99e2-8bfcc85ec207", "node_type": "1", "metadata": {}, "hash": "6bf789337964eb7d83963cdee204a6534b4554034ec3dcfae457deb42f422761", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A. Chowdhery, S. Narang, J. Devlin, M. Bosma,\nG. Mishra, A. Roberts, P. Barham, H. W.\nChung, C. Sutton, S. Gehrmann, P. Schuh,\nK. Shi, S. Tsvyashchenko, J. Maynez, A. Rao,\nP. Barnes, Y. Tay, N. Shazeer, V. Prabhakaran,\nE. Reif, N. Du, B. Hutchinson, R. Pope, J. Brad-\nbury, J. Austin, M. Isard, G. Gur-Ari, P. Yin,\nT. Duke, A. Levskaya, S. Ghemawat, S. Dev,\nH. Michalewski, X. Garcia, V. Misra, K. Robin-\nson, L. Fedus, D. Zhou, D. Ippolito, D. Luan,\nH. Lim, B. Zoph, A. Spiridonov, R. Sepassi,\nD. Dohan, S. Agrawal, M. Omernick, A. M. Dai,\nT.S.Pillai, M.Pellat, A.Lewkowycz, E.Moreira,\nR. Child, O. Polozov, K. Lee, Z. Zhou, X. Wang,\nB. Saeta, M. Diaz, O. Firat, M. Catasta, J. Wei,\nK. Meier-Hellstern, D. Eck, J. Dean, S. Petrov,\nand N. Fiedel. Palm: Scaling language model-\ning with pathways, 2022.\nH. W. Chung, N. Constant, X. Garcia, A. Roberts,\nY. Tay, S. Narang, and O. Firat. Unimax: Fairer\nandmoreeffectivelanguagesamplingforlarge-\nscale multilingual pretraining, 2023.\nC. Clark, K. Lee, M. Chang, T. Kwiatkowski,\nM. Collins, and K. Toutanova. Boolq: Explor-\ning the surprising difficulty of natural yes/no\nquestions. CoRR, abs/1905.10044, 2019.", "mimetype": "text/plain", "start_char_idx": 1225, "end_char_idx": 2379, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "80d80fec-a578-4e90-99e2-8bfcc85ec207": {"__data__": {"id_": "80d80fec-a578-4e90-99e2-8bfcc85ec207", "embedding": null, "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "99c30108165f4694fa21dc44e2ee9d75ece6ff6e8e4d7bdfdd02c8490f72699a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e0d7472-f62f-406b-b43f-faa42fc4683b", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9b6507e32f6b42b86537a8edd5f737843ff3ab7bb1b1a97e6e457c5f83d2709a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3140db75-6905-4826-a178-da5318de796e", "node_type": "1", "metadata": {}, "hash": "d3c3e3de12e3ffe1d934579cb1795216aacc01313560000faab57690b298e723", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen,\nH. Jun, L. Kaiser, M. Plappert, J. Tworek,\nJ. Hilton, R. Nakano, C. Hesse, and J. Schul-\nman. Training verifiers to solve math word\nproblems. CoRR, abs/2110.14168, 2021.\nDeepSeek-AI. Deepseek-r1: Incentivizing reason-\ningt learning, 2025.\nM. Dehghani, J. Djolonga, B. Mustafa,\nP. Padlewski, J. Heek, J. Gilmer, A. P. Steiner,\nM. Caron, R. Geirhos, I. Alabdulmohsin, et al.\nScaling vision transformers to 22 billion\nparameters. InICML, 2023.\nD. Deutsch, E. Briakou, I. Caswell, M. Finkelstein,\nR. Galor, J. Juraska, G. Kovacs, A. Lui, R. Rei,\nJ. Riesa, S. Rijhwani, P. Riley, E. Salesky, F. Tra-\nbelsi, S. Winkler, B. Zhang, and M. Freitag.\nWmt24++: Expanding the language coverage\nof wmt24 to 55 languages & dialects, 2025.\nA. Dosovitskiy. An image is worth 16x16 words:\nTransformers for image recognition at scale.\narXiv preprint arXiv:2010.11929, 2020.\nD. Dua, Y. Wang, P. Dasigi, G. Stanovsky, S. Singh,\nand M. Gardner. DROP: A reading comprehen-\nsion benchmark requiring discrete reasoning\nover paragraphs. InACL, 2019.\nB. Fatemi, M. Kazemi, A. Tsitsulin, K. Malkan,\nJ. Yim, J. Palowitch, S. Seo, J. Halcrow, and\nB. Perozzi.", "mimetype": "text/plain", "start_char_idx": 2380, "end_char_idx": 3553, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3140db75-6905-4826-a178-da5318de796e": {"__data__": {"id_": "3140db75-6905-4826-a178-da5318de796e", "embedding": null, "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2457bb4d-9a66-48d6-b4b5-fc3c102fd0a0", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "99c30108165f4694fa21dc44e2ee9d75ece6ff6e8e4d7bdfdd02c8490f72699a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "80d80fec-a578-4e90-99e2-8bfcc85ec207", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7b1788157214b241530a624720018b5ac3b962ffa941c8dda3b4e7ae6fb1d92d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Test of time: A benchmark for\nevaluating llms on temporal reasoning.arXiv\npreprint arXiv:2406.09170, 2024.\nX. Fu, Y. Hu, B. Li, Y. Feng, H. Wang, X. Lin,\nD. Roth, N. A. Smith, W.-C. Ma, and R. Krishna.\nBlink: Multimodal large language models can\nsee but not perceive.ArXiv, abs/2404.12390,\n2024.\n12", "mimetype": "text/plain", "start_char_idx": 3554, "end_char_idx": 3852, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e80259e-3cc1-4133-b552-80263eec164a": {"__data__": {"id_": "7e80259e-3cc1-4133-b552-80263eec164a", "embedding": null, "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1b81acaa-761e-44c7-92ec-2cbe8675743b", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "35f5e379f06c21d5a1f58165a55056e3c4c23a98e4f3a96642bf646d91441644", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b5dd3fe9-6ada-4e1b-b168-0a8bc36d47a8", "node_type": "1", "metadata": {}, "hash": "a4631eaa8228ecf98702e103b027aff9068ac1c9d4c453b8d63d0cacb4a65627", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nJ. Gehring, K. Zheng, J. Copet, V. Mella, T. Cohen,\nand G. Synnaeve. Rlef: Grounding code llms in\nexecution feedback with reinforcement learn-\ning. arXiv preprint arXiv:2410.02089, 2024.\nGemini Team. Gemini: A family of highly capable\nmultimodal models, 2023.\nGemini Team. Gemini 1.5: Unlocking multimodal\nunderstanding across millions of tokens of con-\ntext, 2024.\nGemma Team. Gemma: Open models based on\ngemini research and technology, 2024a.\nGemma Team. Gemma 2: Improving open lan-\nguage models at a practical size.arXiv preprint\narXiv:2408.00118, 2024b.\nO. Goldman, U. Shaham, D. Malkin, S. Eiger,\nA. Hassidim, Y. Matias, J. Maynez, A. M. Gi-\nlady, J.Riesa, S.Rijhwani, L.Rimell, I.Szpektor,\nR. Tsarfaty, and M. Eyal. Eclektic: a novel chal-\nlenge set for evaluation of cross-lingual knowl-\nedge transfer, 2025.\nN. Goyal, C. Gao, V. Chaudhary, P.-J. Chen,\nG. Wenzek, D. Ju, S. Krishnan, M. Ranzato,\nF. Guzm\u00e1n, and A. Fan. The flores-101 evalua-\ntion benchmark for low-resource and multilin-\ngual machine translation.ACL, 2022.\nY. Goyal, T. Khot, D. Summers-Stay, D. Batra, and\nD. Parikh. Making the V in VQA matter: Elevat-\ning the role of image understanding in Visual\nQuestion Answering. InCVPR, 2017.\nD. Hendrycks, C. Burns, S. Basart, A. Zou,\nM. Mazeika, D. Song, and J. Steinhardt.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1316, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b5dd3fe9-6ada-4e1b-b168-0a8bc36d47a8": {"__data__": {"id_": "b5dd3fe9-6ada-4e1b-b168-0a8bc36d47a8", "embedding": null, "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1b81acaa-761e-44c7-92ec-2cbe8675743b", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "35f5e379f06c21d5a1f58165a55056e3c4c23a98e4f3a96642bf646d91441644", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e80259e-3cc1-4133-b552-80263eec164a", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "95f1967dcf1675aa029294bef5d4bf7c87ced85323cabd4d977abadbb73c5322", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "19058b0e-1e94-4a99-9eae-c8f8f07dce83", "node_type": "1", "metadata": {}, "hash": "daf74b0d3eeee67e6ba40bc96d1747f3531a873048634f4671fd2b4e84cbe13d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Mea-\nsuring massive multitask language understand-\ning. CoRR, abs/2009.03300, 2020.\nD. Hendrycks, C. Burns, S. Kadavath, A. Arora,\nS. Basart, E. Tang, D. Song, and J. Steinhardt.\nMeasuring mathematical problem solving with\nthe math dataset.NeurIPS, 2021.\nJ. Hessel, A. Marasovi\u0107, J. D. Hwang, L. Lee, J. Da,\nR. Zellers, R. Mankoff, and Y. Choi. Do an-\ndroids laugh at electric sheep? humor\" under-\nstanding\"benchmarksfromthenewyorkercap-\ntion contest.arXiv preprint arXiv:2209.06293,\n2022.\nG. Hinton, O. Vinyals, and J. Dean. Distilling the\nknowledge in a neural network.arXiv preprint\narXiv:1503.02531, 2015.\nC.-P. Hsieh, S. Sun, S. Kriman, S. Acharya,\nD. Rekesh, F. Jia, Y. Zhang, and B. Ginsburg.\nRuler: What\u2019s the real context size of your\nlong-context language models?arXiv preprint\narXiv:2404.06654, 2024.\nD. Ippolito, F. Tram\u00e8r, M. Nasr, C. Zhang,\nM. Jagielski, K. Lee, C. A. Choquette-Choo, and\nN. Carlini. Preventing verbatim memorization\nin language models gives a false sense of pri-\nvacy. arXiv preprint arXiv:2210.17546, 2022.\nB. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang,\nA. Howard, H. Adam, and D. Kalenichenko.\nQuantization and training of neural networks\nfor efficient integer-arithmetic-only inference.\nIn CVPR, 2018.\nM. Joshi, E. Choi, D. S. Weld, and L. Zettlemoyer.", "mimetype": "text/plain", "start_char_idx": 1317, "end_char_idx": 2604, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "19058b0e-1e94-4a99-9eae-c8f8f07dce83": {"__data__": {"id_": "19058b0e-1e94-4a99-9eae-c8f8f07dce83", "embedding": null, "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1b81acaa-761e-44c7-92ec-2cbe8675743b", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "35f5e379f06c21d5a1f58165a55056e3c4c23a98e4f3a96642bf646d91441644", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b5dd3fe9-6ada-4e1b-b168-0a8bc36d47a8", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "6b3c4ace3a19ea08c47cd3684646d23f799af0ae1f2dc03d8b0062cd087168a3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Triviaqa: A large scale distantly supervised\nchallenge dataset for reading comprehension.\nCoRR, abs/1705.03551, 2017.\nM. Kazemi, H. Alvari, A. Anand, J. Wu, X. Chen,\nand R. Soricut. Geomverse: A systematic eval-\nuation of large models for geometric reasoning.\narXiv preprint arXiv:2312.12241, 2023.\nM. Kazemi, N. Dikkala, A. Anand, P. Devi\u0107, I. Das-\ngupta, F. Liu, B. Fatemi, P. Awasthi, D. Guo,\nS. Gollapudi, and A. Qureshi. Remi: A dataset\nfor reasoning with multiple images. ArXiv,\nabs/2406.09175, 2024a.\nM. Kazemi, Q. Yuan, D. Bhatia, N. Kim,\nX. Xu, V. Imbrasaite, and D. Ramachandran.\nBoardgameqa: A dataset for natural lan-\nguage reasoning with contradictory informa-\ntion. NeurIPS, 36, 2024b.\nM. Kazemi, B. Fatemi, H. Bansal, J. Palowitch,\nC.Anastasiou, S.V.Mehta, L.K.Jain, V.Aglietti,\nD. Jindal, P. Chen, et al. Big-bench extra hard.\narXiv preprint arXiv:2502.19187, 2025.\nA. Kembhavi, M. Salvato, E. Kolve, M. Seo, H. Ha-\njishirzi, and A. Farhadi. A diagram is worth a\ndozen images.ArXiv, abs/1603.07396, 2016.\n13", "mimetype": "text/plain", "start_char_idx": 2605, "end_char_idx": 3628, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "979d53bd-b996-4067-9c75-2d6311d1cc52": {"__data__": {"id_": "979d53bd-b996-4067-9c75-2d6311d1cc52", "embedding": null, "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "40ee037e-52af-4da7-b433-f00011acab8d", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "d98d1098b669d3b14419953afd4ea314a795c2f675d5b82716fe825922990f28", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "831dec67-ed67-41d7-aa5d-28199b50d00a", "node_type": "1", "metadata": {}, "hash": "9c10ef19641cdde810b9a0965b3f45a210efdde869a73ccb665a3d7a698cce92", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nE. K\u0131c\u0131man, R. Ness, A. Sharma, and C. Tan.\nCausal reasoning and large language models:\nOpening a new frontier for causality. arXiv\npreprint arXiv:2305.00050, 2023.\nT. Kudo and J. Richardson. SentencePiece: A\nsimple and language independent subword to-\nkenizer and detokenizer for neural text pro-\ncessing. 2018.\nT. Kwiatkowski, J. Palomaki, O. Redfield,\nM. Collins, A. Parikh, C. Alberti, D. Epstein,\nI. Polosukhin, J. Devlin, K. Lee, K. Toutanova,\nL. Jones, M. Kelcey, M.-W. Chang, A. M. Dai,\nJ. Uszkoreit, Q. Le, and S. Petrov. Natural ques-\ntions: A benchmark for question answering re-\nsearch. ACL, 2019.\nN. Lambert, J. Morrison, V. Pyatkin, S. Huang,\nH. Ivison, F. Brahman, L. J. V. Miranda, A. Liu,\nN. Dziri, S. Lyu, et al. T\\\" ulu 3: Pushing\nfrontiers in open language model post-training.\narXiv preprint arXiv:2411.15124, 2024.\nZ. Lin, J. Cui, X. Liao, and X. Wang. Malla: De-\nmystifying real-world large language model\nintegrated malicious services, 2024.\nH. Liu, C. Li, Q. Wu, and Y. J. Lee. Visual instruc-\ntion tuning.NeurIPS, 36, 2024.\nLLaMa Team. The llama 3 herd of models.arXiv\npreprint arXiv:2407.21783, 2024.\nM. Luong, H. Pham, and C. D. Manning. Effective\napproaches to attention-based neural machine\ntranslation. 2015.\nMacknight, Aung, and Gomes. Personal Commu-\nnication.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1318, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "831dec67-ed67-41d7-aa5d-28199b50d00a": {"__data__": {"id_": "831dec67-ed67-41d7-aa5d-28199b50d00a", "embedding": null, "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "40ee037e-52af-4da7-b433-f00011acab8d", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "d98d1098b669d3b14419953afd4ea314a795c2f675d5b82716fe825922990f28", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "979d53bd-b996-4067-9c75-2d6311d1cc52", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "51d855502a7cd4fd7076d15884f70737671e3705c7824ef51c4273426af18c73", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e2667920-a83d-457e-8c7b-74d65e73358e", "node_type": "1", "metadata": {}, "hash": "26638995bea22e806695c614f41cb16937b620e5acfee698b0022662832ee07b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Personal Commu-\nnication.\nK. Marino, M. Rastegari, A. Farhadi, and R. Mot-\ntaghi. Ok-vqa: A visual question answering\nbenchmark requiring external knowledge. In\nCVPR, 2019.\nA. Masry, X. L. Do, J. Q. Tan, S. Joty, and E. Hoque.\nChartQA: A benchmark for question answering\nabout charts with visual and logical reasoning.\nACL, 2022.\nM. Mathew, D. Karatzas, R. Manmatha, and C. V.\nJawahar. Docvqa: A dataset for vqa on docu-\nment images.WACV, 2020.\nM. Mathew, V. Bagal, R. Tito, D. Karatzas, E. Val-\nveny, and C. Jawahar. Infographicvqa. InWACV,\n2022.\nI. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel,\nS. Bengio, and M. Farajtabar. Gsm-symbolic:\nUnderstanding the limitations of mathemati-\ncal reasoning in large language models.arXiv\npreprint arXiv:2410.05229, 2024.\nM. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F.\nCooper, D. Ippolito, C. A. Choquette-Choo,\nE. Wallace, F. Tram\u00e8r, and K. Lee. Scal-\nable extraction of training data from (pro-\nduction) language models. arXiv preprint\narXiv:2311.17035, 2023.\nA. Nie, Y. Zhang, A. S. Amdekar, C. Piech, T. B.\nHashimoto, and T. Gerstenberg. Moca: Mea-\nsuring human-language model alignment on\ncausal and moral judgment tasks.NeurIPS, 36,\n2024.\nR. Paiss, A. Ephrat, O. Tov, S. Zada, I. Mosseri,\nM. Irani, and T. Dekel.", "mimetype": "text/plain", "start_char_idx": 1293, "end_char_idx": 2558, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e2667920-a83d-457e-8c7b-74d65e73358e": {"__data__": {"id_": "e2667920-a83d-457e-8c7b-74d65e73358e", "embedding": null, "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "40ee037e-52af-4da7-b433-f00011acab8d", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "d98d1098b669d3b14419953afd4ea314a795c2f675d5b82716fe825922990f28", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "831dec67-ed67-41d7-aa5d-28199b50d00a", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "b4c469b758f26c4d02803f4fd401cab7c5f0f21565f3bce6bc3bdfd9244bce1d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Teaching clip to count\nto ten.ICCV, 2023.\nM. Phuong, M. Aitchison, E. Catt, S. Co-\ngan, A. Kaskasoli, V. Krakovna, D. Lindner,\nM. Rahtz, Y. Assael, S. Hodkinson, H. Howard,\nT. Lieberum, R. Kumar, M. A. Raad, A. Webson,\nL. Ho, S. Lin, S. Farquhar, M. Hutter, G. Dele-\ntang, A. Ruoss, S. El-Sayed, S. Brown, A. Dra-\ngan, R. Shah, A. Dafoe, and T. Shevlane. Evalu-\natingfrontiermodelsfordangerouscapabilities,\n2024.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh,\nG. Goh, S. Agarwal, G. Sastry, A. Askell,\nP. Mishkin, J. Clark, et al. Learning transferable\nvisual models from natural language supervi-\nsion. InICML, pages 8748\u20138763. PMLR, 2021.\nA. Ram\u00e9, J. Ferret, N. Vieillard, R. Dadashi,\nL. Hussenot, P.-L. Cedoz, P. G. Sessa, S. Girgin,\nA. Douillard, and O. Bachem. WARP: On the\nbenefits of weight averaged rewarded policies,\n2024a.\nA. Ram\u00e9, N. Vieillard, L. Hussenot, R. Dadashi,\nG. Cideron, O. Bachem, and J. Ferret. WARM:\nOnthebenefitsofweightaveragedrewardmod-\nels. InICML, 2024b.\n14", "mimetype": "text/plain", "start_char_idx": 2559, "end_char_idx": 3545, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e9c19ca0-dbb0-4608-8628-3beb7e822fd8": {"__data__": {"id_": "e9c19ca0-dbb0-4608-8628-3beb7e822fd8", "embedding": null, "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "234c40b0-589f-4ecd-a685-da31379e778e", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "322bfde65ab95f3092f2a9107c73b55d92b50219389453d912b9d5579f3abee9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3891e37a-b49d-43ec-8529-c4b23f6ded5d", "node_type": "1", "metadata": {}, "hash": "3aabf0d1f3d7ffdc21c4c5ad8fda35996c4f7ded0fbdb63749e53db52fe6a3da", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nD. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y.\nPang, J. Dirani, J. Michael, and S. R. Bow-\nman. Gpqa: A graduate-level google-proof q&a\nbenchmark. ArXiv, abs/2311.12022, 2023.\nJ. Ren, S. Rajbhandari, R. Y. Aminabadi,\nO. Ruwase, S. Yang, M. Zhang, D. Li, and\nY. He. Zero-offload: Democratizing billion-\nscale model training. InUSENIX, 2021.\nA. Roberts, H. W. Chung, G. Mishra, A. Levskaya,\nJ. Bradbury, D. Andor, S. Narang, B. Lester,\nC. Gaffney, A. Mohiuddin, et al. Scaling up\nmodels and data with t5x and seqio.JMLR,\n2023.\nN. Sachdeva, B. Coleman, W.-C. Kang, J. Ni,\nL. Hong, E. H. Chi, J. Caverlee, J. McAuley, and\nD. Z. Cheng. How to train data-efficient llms.\narXiv preprint arXiv:2402.09668, 2024.\nK. Sakaguchi, R. L. Bras, C. Bhagavatula, and\nY. Choi. WINOGRANDE: an adversarial\nwinograd schema challenge at scale. CoRR,\nabs/1907.10641, 2019.\nE. S\u00e1nchez, B. Alastruey, C. Ropers, P. Stenetorp,\nM. Artetxe, and M. R. Costa-juss\u00e0. Linguini:\nA benchmark for language-agnostic linguistic\nreasoning. arXiv preprint arXiv:2409.12126,\n2024.\nM. Sap, H. Rashkin, D. Chen, R. L. Bras,\nand Y. Choi. Socialiqa: Commonsense\nreasoning about social interactions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1185, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3891e37a-b49d-43ec-8529-c4b23f6ded5d": {"__data__": {"id_": "3891e37a-b49d-43ec-8529-c4b23f6ded5d", "embedding": null, "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "234c40b0-589f-4ecd-a685-da31379e778e", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "322bfde65ab95f3092f2a9107c73b55d92b50219389453d912b9d5579f3abee9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e9c19ca0-dbb0-4608-8628-3beb7e822fd8", "node_type": "1", "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "7114133fcca04b9610075118c16cf3a7b2d6ff4172eec8e00d2c71271956096e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d645c9e-e77e-4ccd-be3a-3b5fec5f0cbc", "node_type": "1", "metadata": {}, "hash": "ad06ac0e2eddb2d97e5efc5d70da050e35ec6ebd75bef7962a424c9063b84951", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "CoRR,\nabs/1904.09728, 2019.\nP. G. Sessa, R. Dadashi, L. Hussenot, J. Ferret,\nN. Vieillard, A. Ram\u00e9, B. Shariari, S. Perrin,\nA. Friesen, G. Cideron, S. Girgin, P. Stanczyk,\nA. Michi, D. Sinopalnikov, S. Ramos, A. H\u00e9liou,\nA. Severyn, M. Hoffman, N. Momchev, and\nO. Bachem. Bond: Aligning llms with best-of-n\ndistillation, 2024.\nK. Shah, N. Dikkala, X. Wang, and R. Panigrahy.\nCausal language modeling can elicit search and\nreasoning capabilities on logic puzzles.arXiv\npreprint arXiv:2409.10502, 2024.\nT. Shevlane, S. Farquhar, B. Garfinkel, M. Phuong,\nJ. Whittlestone, J. Leung, D. Kokotajlo, N. Mar-\nchal, M. Anderljung, N. Kolt, L. Ho, D. Sid-\ndarth, S. Avin, W. Hawkins, B. Kim, I. Gabriel,\nV. Bolina, J. Clark, Y. Bengio, P. Christiano, and\nA. Dafoe. Model evaluation for extreme risks,\n2023.\nF. Shi, M. Suzgun, M. Freitag, X. Wang, S. Sri-\nvats, S. Vosoughi, H. W. Chung, Y. Tay, S. Ruder,\nD. Zhou, D. Das, and J. Wei. Language models\nare multilingual chain-of-thought reasoners. In\nICLR, 2023.\nA. Singh, V. Natarjan, M. Shah, Y. Jiang, X. Chen,\nD. Parikh, and M. Rohrbach. Towards vqa mod-\nels that can read. InCVPR, 2019.", "mimetype": "text/plain", "start_char_idx": 1186, "end_char_idx": 2313, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6d645c9e-e77e-4ccd-be3a-3b5fec5f0cbc": {"__data__": {"id_": "6d645c9e-e77e-4ccd-be3a-3b5fec5f0cbc", "embedding": null, "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "234c40b0-589f-4ecd-a685-da31379e778e", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "322bfde65ab95f3092f2a9107c73b55d92b50219389453d912b9d5579f3abee9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3891e37a-b49d-43ec-8529-c4b23f6ded5d", "node_type": "1", "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "dd64ff3934fdc276157bddb769cd7f3f0870f82142b5b3904dbc7ee1a8b0f8e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "602c45a8-34ed-4c9d-8360-e061daaded0f", "node_type": "1", "metadata": {}, "hash": "c719ee23f0d74ee8f531cbb968b5c90e65f91bba9f78f38ac6f0373a555e6af0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "InCVPR, 2019.\nH. Singh, N. Gupta, S. Bharadwaj, D. Tewari,\nand P. Talukdar. Indicgenbench: a multilin-\ngual benchmark to evaluate generation capabil-\nities of llms on indic languages.arXiv preprint\narXiv:2404.16816, 2024a.\nS. Singh, A. Romanou, C. Fourrier, D. I. Adelani,\nJ. G. Ngui, D. Vila-Suero, P. Limkonchotiwat,\nK. Marchisio, W. Q. Leong, Y. Susanto, R. Ng,\nS. Longpre, W.-Y. Ko, M. Smith, A. Bosselut,\nA. Oh, A. F. T. Martins, L. Choshen, D. Ippolito,\nE. Ferrante, M. Fadaee, B. Ermis, and S. Hooker.\nGlobal mmlu: Understanding and addressing\ncultural and linguistic biases in multilingual\nevaluation, 2024b.\nA. Steiner, A. S. Pinto, M. Tschannen, D. Key-\nsers, X. Wang, Y. Bitton, A. Gritsenko, M. Min-\nderer, A. Sherbondy, S. Long, S. Qin, R. In-\ngle, E. Bugliarello, S. Kazemzadeh, T. Mes-\nnard, I. Alabdulmohsin, L. Beyer, and X. Zhai.\nPaliGemma 2: A Family of Versatile VLMs\nfor Transfer.arXiv preprint arXiv:2412.03555,\n2024.\nM. Suzgun, N. Scales, N. Sch\u00e4rli, S. Gehrmann,\nY. Tay, H. W. Chung, A. Chowdhery, Q. V. Le,\nE. H. Chi, D. Zhou, and J. Wei. Challenging\nbig-bench tasks and whether chain-of-thought\ncan solve them, 2022.", "mimetype": "text/plain", "start_char_idx": 2300, "end_char_idx": 3442, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "602c45a8-34ed-4c9d-8360-e061daaded0f": {"__data__": {"id_": "602c45a8-34ed-4c9d-8360-e061daaded0f", "embedding": null, "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "234c40b0-589f-4ecd-a685-da31379e778e", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "322bfde65ab95f3092f2a9107c73b55d92b50219389453d912b9d5579f3abee9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6d645c9e-e77e-4ccd-be3a-3b5fec5f0cbc", "node_type": "1", "metadata": {"page_label": "15", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "801ba71604aa924152bfed89b26d05d2358c2a26030b75889e09035436d0fbd9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "G. Tyen, H. Mansoor, P. Chen, T. Mak, and\nV. C\u0103rbune. Llms cannot find reasoning er-\nrors, but can correct them! arXiv preprint\narXiv:2311.08516, 2023.\nA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,\nL. Jones, A. N. Gomez, L. Kaiser, and I. Polo-\nsukhin. Attention is all you need. 2017.\n15", "mimetype": "text/plain", "start_char_idx": 3443, "end_char_idx": 3734, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "946056b5-0b10-4bf3-a8de-607f5faedfa8": {"__data__": {"id_": "946056b5-0b10-4bf3-a8de-607f5faedfa8", "embedding": null, "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cb9cdaa-67ea-450a-b4af-b07280e51abf", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "c8738356e376946f0e94b90840aa0cc27d4edadeb64d16ddc8ec845ba7ea6564", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "46233c45-41ff-42ba-b24c-255ec301b738", "node_type": "1", "metadata": {}, "hash": "e2f75a0fb36dc24db83e114b41ce1a63a5a95d2fd30fcd46ac369af86eebf959", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nK. Vodrahalli, S. Ontanon, N. Tripuraneni, K. Xu,\nS. Jain, R. Shivanna, J. Hui, N. Dikkala,\nM. Kazemi, B. Fatemi, et al. Michelangelo:\nLong context evaluations beyond haystacks\nvia latent structure queries. arXiv preprint\narXiv:2409.12640, 2024.\nY. Wang, X. Ma, G. Zhang, Y. Ni, A. Chandra,\nS. Guo, W. Ren, A. Arulraj, X. He, Z. Jiang,\netal. Mmlu-pro: Amorerobustandchallenging\nmulti-task language understanding benchmark.\nIn NeurIPS, 2024.\nL. Weidinger, J. Mellor, M. Rauh, C. Griffin,\nJ. Uesato, P.-S. Huang, M. Cheng, M. Glaese,\nB. Balle, A. Kasirzadeh, Z. Kenton, S. Brown,\nW. Hawkins, T. Stepleton, C. Biles, A. Birhane,\nJ. Haas, L. Rimell, L. A. Hendricks, W. Isaac,\nS. Legassick, G. Irving, and I. Gabriel. Ethical\nand social risks of harm from language models,\n2021.\nC. White, S. Dooley, M. Roberts, A. Pal, B. Feuer,\nS. Jain, R. Shwartz-Ziv, N. Jain, K. Saiful-\nlah, S. Naidu, et al. Livebench: A challeng-\ning, contamination-free llm benchmark.arXiv\npreprint arXiv:2406.19314, 2024.\nM. Wortsman, P. J. Liu, L. Xiao, K. Everett,\nA.Alemi, B.Adlam, J.D.Co-Reyes, I.Gur, A.Ku-\nmar, R. Novak, et al. Small-scale proxies for\nlarge-scale transformer training instabilities.\narXiv preprint arXiv:2309.14322, 2023.\nXLA.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1245, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "46233c45-41ff-42ba-b24c-255ec301b738": {"__data__": {"id_": "46233c45-41ff-42ba-b24c-255ec301b738", "embedding": null, "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cb9cdaa-67ea-450a-b4af-b07280e51abf", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "c8738356e376946f0e94b90840aa0cc27d4edadeb64d16ddc8ec845ba7ea6564", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "946056b5-0b10-4bf3-a8de-607f5faedfa8", "node_type": "1", "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "853d5ec9b08a6792014f5711f1ff68b63c98b244a656e888c72e30bc2b8cb7ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "542022e0-535a-4367-8845-affcda1d2f63", "node_type": "1", "metadata": {}, "hash": "f7b127db2af69c0264e7ab019e4f68b7f481775dd8a2424fc7400e9f972ec14f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "XLA. Xla: Optimizing compiler for tensor-\nflow, 2019. URLhttps://www.tensorflow.\norg/xla.\nY. Xu, H. Lee, D. Chen, B. A. Hechtman, Y. Huang,\nR. Joshi, M. Krikun, D. Lepikhin, A. Ly, M. Mag-\ngioni, R. Pang, N. Shazeer, S. Wang, T. Wang,\nY. Wu, and Z. Chen. GSPMD: general and scal-\nable parallelization for ML computation graphs.\n2021.\nY. Yamada, Y. Bao, A. K. Lampinen, J. Kasai,\nand I. Yildirim. Evaluating spatial understand-\ning of large language models.arXiv preprint\narXiv:2310.14540, 2023.\nK. Yang, O. Russakovsky, and J. Deng. Spa-\ntialsense: An adversarially crowdsourced\nbenchmark for spatial relation recognition.\nICCV, 2019.\nX.Yue, Y.Ni, K.Zhang, T.Zheng, R.Liu, G.Zhang,\nS. Stevens, D. Jiang, W. Ren, Y. Sun, C. Wei,\nB. Yu, R. Yuan, R. Sun, M. Yin, B. Zheng,\nZ. Yang, Y. Liu, W. Huang, H. Sun, Y. Su,\nand W. Chen. Mmmu: A massive multi-\ndiscipline multimodal understanding and rea-\nsoning benchmark for expert agi.CVPR, 2023.\nR. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and\nY.Choi. HellaSwag: Canamachinereallyfinish\nyour sentence? InACL, 2019.\nX. Zhai, B. Mustafa, A. Kolesnikov, and L. Beyer.\nSigmoid loss for language image pre-training.\nIn CVPR, 2023.\nB. Zhang and R. Sennrich. Root mean square\nlayer normalization. 2019.", "mimetype": "text/plain", "start_char_idx": 1241, "end_char_idx": 2479, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "542022e0-535a-4367-8845-affcda1d2f63": {"__data__": {"id_": "542022e0-535a-4367-8845-affcda1d2f63", "embedding": null, "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cb9cdaa-67ea-450a-b4af-b07280e51abf", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "c8738356e376946f0e94b90840aa0cc27d4edadeb64d16ddc8ec845ba7ea6564", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46233c45-41ff-42ba-b24c-255ec301b738", "node_type": "1", "metadata": {"page_label": "16", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9bcf46e180434a7b83222e6d4aad7d8206cc8e04abb511a552ef91ab82d70952", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2019.\nJ. Zhang, L. Jain, Y. Guo, J. Chen, K. L. Zhou,\nS. Suresh, A. Wagenmaker, S. Sievert, T. Rogers,\nK. Jamieson, et al. Humor in ai: Massive\nscale crowd-sourced preferences and bench-\nmarks for cartoon captioning.arXiv preprint\narXiv:2406.10522, 2024.\nW. Zhong, R. Cui, Y. Guo, Y. Liang, S. Lu, Y. Wang,\nA. Saied, W. Chen, and N. Duan. Agieval: A\nhuman-centric benchmark for evaluating foun-\ndation models, 2023.\n16", "mimetype": "text/plain", "start_char_idx": 2474, "end_char_idx": 2892, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd0a4a21-7a9b-4ea5-88b0-d927294f8827": {"__data__": {"id_": "dd0a4a21-7a9b-4ea5-88b0-d927294f8827", "embedding": null, "metadata": {"page_label": "17", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a949a7f4-9c12-4e4c-b600-fc69affde3ce", "node_type": "4", "metadata": {"page_label": "17", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "d9ea27eb54c7abd2da4bc25857b103cb7223bfab14c31f0fca91ecdf3cda3820", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0186f0a7-3712-449c-9d45-85e479b42831", "node_type": "1", "metadata": {}, "hash": "3fcda01eb31e8a5b6ab053684839905a276c57035f6abe041aeaaaea2b3c446f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nCore contributors\nAishwarya Kamath\u2217\nJohan Ferret\u2217\nShreya Pathak\u2217\nNino Vieillard\u2217\nRamona Merhej\u2217\nSarah Perrin\u2217\nTatiana Matejovicova\u2217\nAlexandre Ram\u00e9\u2217\nMorgane Rivi\u00e8re\u2217\nLouis Rouillard\u2217\nThomas Mesnard\u2217\nGeoffrey Cideron\u2217\nJean-bastien Grill\u2217\nSabela Ramos\u2217\nEdouard Yvinec\u2217\nMichelle Casbon\u2217\nEtienne Pot\nIvo Penchev\nGa\u00ebl Liu\nFrancesco Visin\nKathleen Kenealy\nLucas Beyer\nXiaohai Zhai\nAnton Tsitsulin\nRobert Busa-Fekete\nAlex Feng\nNoveen Sachdeva\nBenjamin Coleman\nYi Gao\nBasil Mustafa\nIain Barr\nEmilio Parisotto\nDavid Tian\nMatan Eyal\nColin Cherry\nJan-Thorsten Peter\nDanila Sinopalnikov\nSurya Bhupatiraju\nRishabh Agarwal\nMehran Kazemi\nDan Malkin\nRavin Kumar\nDavid Vilar\nIdan Brusilovsky\nJiaming Luo\nAndreas Steiner\n\u2217co-first authors.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 745, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0186f0a7-3712-449c-9d45-85e479b42831": {"__data__": {"id_": "0186f0a7-3712-449c-9d45-85e479b42831", "embedding": null, "metadata": {"page_label": "17", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a949a7f4-9c12-4e4c-b600-fc69affde3ce", "node_type": "4", "metadata": {"page_label": "17", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "d9ea27eb54c7abd2da4bc25857b103cb7223bfab14c31f0fca91ecdf3cda3820", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dd0a4a21-7a9b-4ea5-88b0-d927294f8827", "node_type": "1", "metadata": {"page_label": "17", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "4d59cd9c83e7f1e1de9638664ba54cea5f601cbef4aa515d77a2e93668a04a58", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Contributors (alphabetical order)\nAbe Friesen\nAbhanshu Sharma\nAbheesht Sharma\nAdi Mayrav Gilady\nAdrian Goedeckemeyer\nAlaa Saade\nAlex Feng\nAlexander Kolesnikov\nAlexei Bendebury\nAlvin Abdagic\nAmit Vadi\nAndr\u00e1s Gy\u00f6rgy\nAndr\u00e9 Susano Pinto\nAnil Das\nAnkur Bapna\nAntoine Miech\nAntoine Yang\nAntonia Paterson\nAshish Shenoy\nAyan Chakrabarti\nBilal Piot\nBo Wu\nBobak Shahriari\nBryce Petrini\nCharlie Chen\nCharline Le Lan\nChristopher A. Choquette-Choo\nCJ Carey\nCormac Brick\nDaniel Deutsch\nDanielle Eisenbud\nDee Cattle\nDerek Cheng\nDimitris Paparas\nDivyashree Shivakumar Sreepathihalli\nDoug Reid\nDustin Tran\nDustin Zelle\nEric Noland\nErwin Huizenga\nEugene Kharitonov\nFrederick Liu\nGagik Amirkhanyan\nGlenn Cameron\nHadi Hashemi\nHanna Klimczak-Pluci\u0144ska\nHarman Singh\nHarsh Mehta\n17", "mimetype": "text/plain", "start_char_idx": 746, "end_char_idx": 1504, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c48bf46e-d1c3-42b0-bd70-71009c65d1e1": {"__data__": {"id_": "c48bf46e-d1c3-42b0-bd70-71009c65d1e1", "embedding": null, "metadata": {"page_label": "18", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b8f45ef9-0e05-4a12-add2-f9a866a51c97", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "caa6cfb2332a03db468c27f8d22bc93488e1a7e2e7ed8f84d828462ae6b39cc2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "564c86aa-edfb-4a58-91f3-231d689f482c", "node_type": "1", "metadata": {}, "hash": "71c2b203b8ff886866bc40e3298ff52cb2c2257b692ffa542f4cb66b579d4384", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nHarshal Tushar Lehri\nHussein Hazimeh\nIan Ballantyne\nIdan Szpektor\nIvan Nardini\nJean Pouget-Abadie\nJetha Chan\nJoe Stanton\nJohn Wieting\nJonathan Lai\nJordi Orbay\nJoseph Fernandez\nJosh Newlan\nJu-yeong Ji\nJyotinder Singh\nKat Black\nKathy Yu\nKevin Hui\nKiran Vodrahalli\nKlaus Greff\nLinhai Qiu\nMarcella Valentine\nMarina Coelho\nMarvin Ritter\nMatt Hoffman\nMatthew Watson\nMayank Chaturvedi\nMichael Moynihan\nMin Ma\nNabila Babar\nNatasha Noy\nNathan Byrd\nNick Roy\nNikola Momchev\nNilay Chauhan\nNoveen Sachdeva\nOskar Bunyan\nPankil Botarda\nPaul Caron\nPaul Kishan Rubenstein\nPhil Culliton\nPhilipp Schmid\nPier Giuseppe Sessa\nPingmei Xu\nPiotr Stanczyk\nPouya Tafti\nRakesh Shivanna\nRenjie Wu\nRenke Pan\nReza Rokni\nRob Willoughby\nRohith Vallu\nRyan Mullins\nSammy Jerome\nSara Smoot\nSertan Girgin\nShariq Iqbal\nShashir Reddy\nShruti Sheth\nSiim P\u00f5der\nSijal Bhatnagar\nSindhu Raghuram Panyam\nSivan Eiger\nSusan Zhang\nTianqi Liu\nTrevor Yacovone\nTyler Liechty\nUday Kalra\nUtku Evci\nVedant Misra\nVincent Roseberry\nVlad Feinberg\nVlad Kolesnikov\nWoohyun Han\nWoosuk Kwon\nXi Chen\nYinlam Chow\nYuvein Zhu\nZichuan Wei\nZoltan Egyed\nSupport\nVictor Cotruta\nMinh Giang\nPhoebe Kirk\nAnand Rao\nKat Black\nNabila Babar\nJessica Lo\nErica Moreira\nLuiz Gustavo Martins\nOmar", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1239, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "564c86aa-edfb-4a58-91f3-231d689f482c": {"__data__": {"id_": "564c86aa-edfb-4a58-91f3-231d689f482c", "embedding": null, "metadata": {"page_label": "18", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b8f45ef9-0e05-4a12-add2-f9a866a51c97", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "caa6cfb2332a03db468c27f8d22bc93488e1a7e2e7ed8f84d828462ae6b39cc2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c48bf46e-d1c3-42b0-bd70-71009c65d1e1", "node_type": "1", "metadata": {"page_label": "18", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9ccdecaea1e39dc77b4c5855cbb857fc9b1301aefd34a200a6b5b38d6aac264c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gustavo Martins\nOmar Sanseviero\nLucas Gonzalez\nZach Gleicher\nTris Warkentin\nSponsors\n18", "mimetype": "text/plain", "start_char_idx": 1219, "end_char_idx": 1306, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7c7caf75-486d-4906-a929-7dce5813c76c": {"__data__": {"id_": "7c7caf75-486d-4906-a929-7dce5813c76c", "embedding": null, "metadata": {"page_label": "19", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed6723b5-7a1c-459f-b8a9-a02444c254c0", "node_type": "4", "metadata": {"page_label": "19", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "58385fcb1daf586a949fb27d71a5e29bbb78174d1b23bf54aee86d1c35767f3d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nVahab Mirrokni\nEvan Senter\nEli Collins\nJoelle Barral\nZoubin Ghahramani\nRaia Hadsell\nYossi Matias\nD. Sculley\nSlav Petrov\nNoah Fiedel\nNoam Shazeer\nOriol Vinyals\nJeff Dean\nDemis Hassabis\nKoray Kavukcuoglu\nClement Farabet\nTechnical advisors\nElena Buchatskaya\nJean-Baptiste Alayrac\nRohan Anil\nDmitry (Dima) Lepikhin\nSebastian Borgeaud\nOlivier Bachem\nLead\nArmand Joulin\nTechnical leads\nAlek Andreev\nCassidy Hardin\nRobert Dadashi\nL\u00e9onard Hussenot\n19", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 467, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c7b9e4eb-a344-4de6-92ee-f7728e64223e": {"__data__": {"id_": "c7b9e4eb-a344-4de6-92ee-f7728e64223e", "embedding": null, "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d170cc4a-480f-419d-9376-e0a822fc7458", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "109f754f95c31ddc75b278bb101f840fb6bb3eca17c7ba23e6b61203156126c6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bce3975b-dd9a-4456-8b4c-834c86790df9", "node_type": "1", "metadata": {}, "hash": "37afacf36d31ca07c67fa90e4641750f295712d454c1a3b658e3366266315ec3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nAppendix\nDetails of pre-trained performances.\nGemma 2 Gemma 3\n2B 9B 27B 1B 4B 12B 27B\nHellaS 72.9 81.9 86.4 62.3 77.2 84.2 85.6\nBoolQ 75.6 77.5 76.2 63.2 72.3 78.8 82.4\nPIQA 78.1 81.9 83.5 73.8 79.6 81.8 83.3\nSIQA 51.8 53.3 53.8 48.9 51.9 53.4 54.9\nTQA 60.2 76.5 83.8 39.8 65.8 78.2 85.5\nNQ 17.2 29.2 34.7 9.48 20.0 31.4 36.1\nARC-C 55.8 69.1 71.4 38.4 56.2 68.9 70.6\nARC-E 80.6 88.3 88.6 73.0 82.4 88.3 89.0\nWinoG 65.4 73.9 79.4 58.2 64.7 74.3 78.8\nBBH 42.4 69.4 74.8 28.4 50.9 72.6 77.7\nDrop 53.2 71.5 75.2 42.4 60.1 72.2 77.2\nTable 9|Factuality, common-sense performance\nand reasoning after pre-training phase.\nFactuality and common-sense.In Table 9, we\nreport the performance of our new pre-trained\nbenchmarks compared to previous versions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 768, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bce3975b-dd9a-4456-8b4c-834c86790df9": {"__data__": {"id_": "bce3975b-dd9a-4456-8b4c-834c86790df9", "embedding": null, "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d170cc4a-480f-419d-9376-e0a822fc7458", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "109f754f95c31ddc75b278bb101f840fb6bb3eca17c7ba23e6b61203156126c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7b9e4eb-a344-4de6-92ee-f7728e64223e", "node_type": "1", "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "f595d291ff0530894f51c17e85add168ae99c558ccde4c6cac7f4a8b083e2adf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6c7ae6ed-40f5-4a0c-a7ef-2c50dc2f5414", "node_type": "1", "metadata": {}, "hash": "06ffe1df7577df437aeae9a5695d71e68e9424c28860a41addf6348d0f85addc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We\nconsider several standard benchmarks, namely\nHellaSwag (Zellers et al., 2019), BoolQ (Clark\net al., 2019), PIQA (Bisk et al., 2019), SIQA (Sap\net al., 2019), TriviaQA (Joshi et al., 2017), Natu-\nral Questions (Kwiatkowski et al., 2019), ARC-C\nand ARC-E (Chollet, 2019), WinoGrande (Sak-\naguchi et al., 2019), BBH (Suzgun et al., 2022),\nDROP (Dua et al., 2019). Evaluation details are\ndescribed in Table 19. Overall, our models are in\nthe same ballpark as Gemma 2, which is encour-\naging since these abilities are not the focus of the\nimprovements brought in this version.\nSTEM and code. The details of our per-\nformance on STEM and Code are in Ta-\nble 10. We consider several standard bench-\nmarks, namely MMLU (Hendrycks et al., 2020),\nMMLU-Pro (Wang et al., 2024), AGIEval (Zhong\net al., 2023), MATH (Hendrycks et al., 2021),\nGSM8K (Cobbe et al., 2021), GPQA (Rein\net al., 2023), MBPP (Austin et al., 2021), Hu-\nmanEval (Chen et al., 2021). Evaluation details\nare described in Table 19.", "mimetype": "text/plain", "start_char_idx": 769, "end_char_idx": 1760, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6c7ae6ed-40f5-4a0c-a7ef-2c50dc2f5414": {"__data__": {"id_": "6c7ae6ed-40f5-4a0c-a7ef-2c50dc2f5414", "embedding": null, "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d170cc4a-480f-419d-9376-e0a822fc7458", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "109f754f95c31ddc75b278bb101f840fb6bb3eca17c7ba23e6b61203156126c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bce3975b-dd9a-4456-8b4c-834c86790df9", "node_type": "1", "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9eaef192991ce7560715b067b95a4bab239dd40c67227197212bf95fdec37883", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e36c5740-185a-4baf-bf72-2c5e15581d80", "node_type": "1", "metadata": {}, "hash": "d45782bb45caebb7420a06bb5ad299d00fd82c2993f710ea91317779ef4adecb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Overall we see a consis-\ntent improvement over STEM abilities across our\nGemma 2 Gemma 3\n2B 9B 27B 4B 12B 27B\nMMLU 52.2 71.2 75.2 59.6 74.5 78.6\nMMLUpro 22.2 43.7 49.4 29.2 45.3 52.2\nAGIE 31.6 53.1 55.1 42.1 57.4 66.2\nMATH 16.4 36.4 42.1 24.2 43.3 50.0\nGSM8K 25.0 70.2 74.6 38.4 71.0 82.6\nGPQA Diamond 12.5 24.8 26.3 15.0 25.4 24.3\nMBPP 31.0 51.2 60.8 46.0 60.4 65.6\nHumanE 19.5 40.2 51.2 36.0 45.7 48.8\nTable 10|STEM and code performance after pre-\ntraining phase.\npre-trained models. On code, we see a similar\nimprovement for the 4B and 12B models but not\non the 27B.", "mimetype": "text/plain", "start_char_idx": 1761, "end_char_idx": 2330, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e36c5740-185a-4baf-bf72-2c5e15581d80": {"__data__": {"id_": "e36c5740-185a-4baf-bf72-2c5e15581d80", "embedding": null, "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d170cc4a-480f-419d-9376-e0a822fc7458", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "109f754f95c31ddc75b278bb101f840fb6bb3eca17c7ba23e6b61203156126c6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6c7ae6ed-40f5-4a0c-a7ef-2c50dc2f5414", "node_type": "1", "metadata": {"page_label": "20", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "4e6692a36082248373a9caab4d2d7e79f7597bd7871b5f8d14731331fcf4bc30", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4B 12B 27B\nCOCO caption 102 111 116\nDocVQA 72.8 82.3 85.6\nInfoVQA 44.1 54.8 59.4\nMMMU 39.2 50.3 56.1\nTextVQA 58.9 66.5 68.6\nRealWorldQA 45.5 52.2 53.9\nReMI 27.3 38.5 44.8\nAI2D 63.2 75.2 79.0\nChartQA 63.6 74.7 76.3\nVQAv2 63.9 71.2 72.9\nBLINK 38.0 35.9 39.6\nOK-VQA 51.0 58.7 60.2\nTallyQA 42.5 51.8 54.3\nSpatialSense VQA 50.9 60.0 59.4\nCountBench VQA 26.1 17.8 68.0\nTable 11 |Multimodal performance after pre-\ntraining phase. The scores are on the val split\nof each dataset without P&S.\nImage understanding. In Table 11, we re-\nport performance across a variety of visual\nquestion answer benchmarks for the different\nmodels that were trained with a vision en-\ncoder, namely COCO Caption (Chen et al.,\n2015), DocVQA (Mathew et al., 2020), Info-\ngraphicVQA (Mathew et al., 2022), MMMU (Yue\net al., 2023), TextVQA (Singh et al., 2019), Re-\nalWorldQA (Rea), ReMI (Kazemi et al., 2024a),\n20", "mimetype": "text/plain", "start_char_idx": 2331, "end_char_idx": 3213, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a2944bdd-1ba4-40eb-9fc9-cef6a660039b": {"__data__": {"id_": "a2944bdd-1ba4-40eb-9fc9-cef6a660039b", "embedding": null, "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fccb58ca-7e57-49dd-989b-831eed15e271", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "5e0c8dcee58ec94a0f7216f44138cb6a347835e5021e8205165be00327578023", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cf89f48b-46ab-4a30-aad0-e77d4b8fe471", "node_type": "1", "metadata": {}, "hash": "1ffc658d307b6165d57e96d9ce309a15022ceafa221e0483cfb704086dbb43a2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nAI2D (Kembhavi et al., 2016), ChartQA (Masry\net al., 2022), VQA v2 (Goyal et al., 2017),\nBLINK (Fu et al., 2024), OK-VQA (Marino et al.,\n2019), TallyQA (Acharya et al., 2018), Spa-\ntialSense VQA (Yang et al., 2019), CountBench\nVQA (Paiss et al., 2023). Evaluation details are\ndescribed in Table 20.\nPaliGemma 2 Gemma 3\n2B 9B 27B 4B 12B 27B\nDocVQA 81.6 86.3 85.1 86.1 89.0 89.5\nInfoVQA 41.4 53.1 50.2 55.6 61.6 64.6\nTextVQA 76.3 76.3 75.1 79.1 81.6 83.2\nChartQA 70.7 79.1 71.3 79.8 83.5 83.4\nAI2D 76.0 84.4 84.6 80.9 85.6 86.5\nOKVQA 64.1 68.6 70.6 65.2 69.3 71.1\nCountBenchQA 82.0 85.3 87.4 79.4 83.5 87.8\nCOCO caption 143. 145. 145. 143. 143. 144.\nVQAv2 84.8 85.8 85.8 84.1 84.9 85.1\nTally QA 80.6 82.4 82.1 79.0 81.3 81.7\nTable 12|Performance of pre-trained checkpoints\nafter fine-tuning on multi-modal benchmarks\n(without P&S). PaliGemma 2 was transferred at\n896x896 resolution for the first four benchmarks,\nand at 448x448 resolution for the others.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 977, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cf89f48b-46ab-4a30-aad0-e77d4b8fe471": {"__data__": {"id_": "cf89f48b-46ab-4a30-aad0-e77d4b8fe471", "embedding": null, "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fccb58ca-7e57-49dd-989b-831eed15e271", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "5e0c8dcee58ec94a0f7216f44138cb6a347835e5021e8205165be00327578023", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2944bdd-1ba4-40eb-9fc9-cef6a660039b", "node_type": "1", "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "1e42f765ff5ddd796e72f8453cbf2e4722a41aac89317a8e2e095a8a68586b61", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "97de8706-944d-4adb-b275-4f8a65a7eb4e", "node_type": "1", "metadata": {}, "hash": "68e4df771ba7b3451abb1d93689f791ddba017935960a37b9ec4ac16c3eaef9b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Comparison to PaliGemma 2.We fine-tune mul-\ntimodal Gemma 3 pre-trained checkpoints fol-\nlowing the protocol from Steiner et al. (2024) \u2013\nonly learning rate is swept, otherwise the same\ntransfer settings are used. The results in Table 12\nshow that Gemma 3 excels at benchmarks in-\nvolving document understanding, even outper-\nforming thelarger PaliGemma 2 variant. Note\nthat due to average pooling in the vision en-\ncoder the Gemma 3 4B and 12B models are\nabout 10x cheaper to transfer compared with the\nPaliGemma 2 9B and 27B models at the same 896\nx 896 resolution. Gemma 3 also performs better\non AI2D and OKVQA, but PaliGemma 2 performs\nslightly better on VQAv2 and COCO caption.\nMultilinguality. In Table 13 we report the per-\nformance of the pre-trained models on multilin-\ngual tasks.", "mimetype": "text/plain", "start_char_idx": 978, "end_char_idx": 1769, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "97de8706-944d-4adb-b275-4f8a65a7eb4e": {"__data__": {"id_": "97de8706-944d-4adb-b275-4f8a65a7eb4e", "embedding": null, "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fccb58ca-7e57-49dd-989b-831eed15e271", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "5e0c8dcee58ec94a0f7216f44138cb6a347835e5021e8205165be00327578023", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cf89f48b-46ab-4a30-aad0-e77d4b8fe471", "node_type": "1", "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "9b6255c39a35d1f6066afa5cf24b7e159c70bb2e1eb22e341bf86b44c8ca349d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1af9fa12-5185-4c5c-b872-90331da112b1", "node_type": "1", "metadata": {}, "hash": "c84600f8eb794c71bb7ba5bc6a071e653284cb8bd7f607001e0a590711aec12b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We apply in-context learning with\nmulti-shot prompting and present results on\nthe following benchmarks: MGSM (Shi et al.,\n2023), Global-MMLU-Lite (Singh et al., 2024b),\nWMT24++(Deutschetal.,2025),FLoRes(Goyal\nGemma 2 Gemma 3\n2B 9B 27B 1B 4B 12B 27B\nMGSM 18.7 57.3 68.0 2.04 34.7 64.3 74.3\nGMMLU 43.3 64.0 69.4 24.9 57.0 69.4 75.7\nWMT24++ 38.8 50.3 53.0 36.7 48.4 53.9 55.7\nFlores 30.2 41.3 44.3 29.5 39.2 46.0 48.8\nXQuAD 53.7 72.2 73.9 43.9 68.0 74.5 76.8\nECLeKTic 8.29 14.0 17.1 4.69 11.0 17.2 24.4\nIndicGB 47.4 59.3 62.1 41.4 57.2 61.7 63.4\nTable 13|Multilingual performance after the pre-\ntraining phase. IndicGenBench is an average over\nbenchmarks reported in Table 14.\net al., 2022), XQuAD (Artetxe et al., 2020),\nECLeKTic (Goldman et al., 2025), IndicGen-\nBench (Singh et al., 2024a), XOR QA (Asai et al.,\n2020). Evaluation details are described in Ta-\nble 19.", "mimetype": "text/plain", "start_char_idx": 1770, "end_char_idx": 2636, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1af9fa12-5185-4c5c-b872-90331da112b1": {"__data__": {"id_": "1af9fa12-5185-4c5c-b872-90331da112b1", "embedding": null, "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fccb58ca-7e57-49dd-989b-831eed15e271", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "5e0c8dcee58ec94a0f7216f44138cb6a347835e5021e8205165be00327578023", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "97de8706-944d-4adb-b275-4f8a65a7eb4e", "node_type": "1", "metadata": {"page_label": "21", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "ba343c3c7e429340eef704147a313b0782f618d90eccefc539619cf74e2d5b42", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 2 Gemma 3\n2B 9B 27B 1B 4B 12B 27B\nXQuAD Indic 54.3 73.1 74.9 43.1 68.3 75.2 77.8\nXORQA in-en 66.2 69.372.5 56.3 68.3 69.8 70.4\nXORQA in-xx 31.2 40.8 44.3 27.1 39.8 43.8 46.0\nFlores Indic 38.1 54.0 56.9 39.0 52.3 58.0 59.5\nTable 14|Detailed IndicGenBench performance\nafter the pre-training phase.\nLong context. In Table 15 we report the per-\nformance of pre-trained and fine-tuned mod-\nels on long context benchmarks. We include\nRULER (Hsieh et al., 2024) and MRCR (Vodra-\nhalli et al., 2024) benchmarks evaluating at 32K\nand 128K sequence lengths.\n8.1. Performance of IT models\nWe report in Table 18, additional benchmarks\non our IT models. Note that N2C refers to\nNatural2Code, the Gemini 1.0 internal held-out\ndataset, which uses author-generated sources in-\nstead of web-based information. BBEH refers to\nBIG-Bench Extra Hard (Kazemi et al., 2025), a\nchallengingLLMreasoningbenchmarkthataggre-\ngates several reasoning tasks (Fatemi et al., 2024;\n21", "mimetype": "text/plain", "start_char_idx": 2637, "end_char_idx": 3594, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "47934842-e923-436f-98aa-5c890314a2c2": {"__data__": {"id_": "47934842-e923-436f-98aa-5c890314a2c2", "embedding": null, "metadata": {"page_label": "22", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cc432e08-65eb-41f6-9d68-9b24109c05a9", "node_type": "4", "metadata": {"page_label": "22", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "867ec192a343fa9c2f1ebb2451a756bb0a879d8208942c9fa4faf3442f26b7e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f08ab8f4-6f73-4106-be4b-f39ee7804501", "node_type": "1", "metadata": {}, "hash": "f60fd30cdc62fc3fde2cc63e39202ef26040f7eb6fc6be4ff5765656ebec55f9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nGemma 3 PT Gemma 3 IT\nContext 4B 12B 27B 4B 12B 27B\nRULER 32K 67.1 90.6 85.9 61.4 80.3 91.1\nRULER 128K 51.7 80.7 72.9 46.8 57.1 66.0\nMRCR 32K 44.7 59.8 63.2 49.8 53.7 63.2\nMRCR 128K 40.6 56.9 60.0 44.6 49.8 59.3\nTable 15|Performance of pre-trained (PT) and\ninstructionfine-tuned(IT)modelsonlongcontext\nbenchmarks at different context lengths.\n4B 12B 27B\nMMMU (val) 48.8 59.6 64.9\nDocVQA 75.8 87.1 86.6\nInfoVQA 50.0 64.9 70.6\nTextVQA 57.8 67.7 65.1\nAI2D 74.8 84.2 84.5\nChartQA 68.8 75.7 78.0\nVQAv2 (val) 62.4 71.6 71.0\nMathVista (testmini) 50.0 62.9 67.6\nTable 16|Performance of instruction fine-tuned\n(IT) models on multimodal benchmarks. If not\nmentioned, these results are on the final test set\nof each dataset with P&S applied.\nHessel et al., 2022; Kazemi et al., 2023, 2024b;\nK\u0131c\u0131man et al., 2023; Nie et al., 2024; S\u00e1nchez\net al., 2024; Shah et al., 2024; Tyen et al., 2023;\nWhite et al., 2024; Yamada et al., 2023; Zhang\net al., 2024). ECLeKTic refers to Goldman et al.\n(2025).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1008, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f08ab8f4-6f73-4106-be4b-f39ee7804501": {"__data__": {"id_": "f08ab8f4-6f73-4106-be4b-f39ee7804501", "embedding": null, "metadata": {"page_label": "22", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cc432e08-65eb-41f6-9d68-9b24109c05a9", "node_type": "4", "metadata": {"page_label": "22", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "867ec192a343fa9c2f1ebb2451a756bb0a879d8208942c9fa4faf3442f26b7e5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "47934842-e923-436f-98aa-5c890314a2c2", "node_type": "1", "metadata": {"page_label": "22", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "8efa97e4b9f8f507a7d2c7fd995fce5dc7b01c23cabad8297b7e59f20e0bad60", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(2025). We report the micro average score. More\nevaluation details are described in Table 21.\n8.2. Performance of IT models on video under-\nstanding\nAdditional multimodal evaluations. Gemma\n3 IT models were evaluated on common vision\nbenchmarks following the evaluation protocol of\nGemini 1.5 (Gemini Team, 2024). The results are\ngiven in Table 16 when P&S is activated.\n4B 12B 27B\nPerception Test MCVQA 50.6 54.9 58.1\nActivityNet-QA 46.3 50.4 52.8\nTable 17|Performance of instruction fine-tuned\n(IT) models on vision understanding benchmarks\nusing 0 shot with 16 frames linspace. Per-\nception Test consists of real-world videos de-\nsigned to show perceptually interesting situa-\ntions and we report results on the multiple choice\nvideo QA benchmark in terms of top-1 accuracy.\nActivityNet-QA reports standard gpt-evaluation.\n22", "mimetype": "text/plain", "start_char_idx": 1001, "end_char_idx": 1829, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "46bac1e0-24f2-47b7-bcc4-2658e48bb970": {"__data__": {"id_": "46bac1e0-24f2-47b7-bcc4-2658e48bb970", "embedding": null, "metadata": {"page_label": "23", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cc17eec2-f6a5-4b74-af6a-6e4f184413fe", "node_type": "4", "metadata": {"page_label": "23", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "aa27c89f5d58e590896772eb725c95f1e1c796e3e32e4090149c6248837de26e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8d4f9b2b-18bc-488c-bd53-74d4298adf19", "node_type": "1", "metadata": {}, "hash": "0bd2126aa70a845eaed74edc5182112051df98579752515a4d3eb1ac9f369bfd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nGemma 2 Gemma 3\n2B 9B 27B 1B 4B 12B 27B\nMMLU 56.1 71.3 76.2 38.8 58.1 71.9 76.9\nMBPP 36.6 59.2 67.4 35.2 63.2 73.0 74.4\nHumanEval 20.1 40.2 51.8 41.5 71.3 85.4 87.8\nN2C 46.8 68.3 77.3 56.0 70.3 80.7 84.5\nLiveCodeBench 7.0 20.0 29.0 5.0 23.0 32.0 39.0\nGSM8K 62.6 88.1 91.1 62.8 89.2 94.4 95.9\nMATH 27.2 49.4 55.6 48.0 75.6 83.8 89.0\nHiddenMath 2.0 8.0 12.0 15.0 42.0 51.0 56.0\nBBH 41.4 69.0 74.9 39.1 72.2 85.7 87.6\nBBEH 5.9 9.8 14.8 7.2 11.0 16.3 19.3\nIFEval 80.4 88.4 91.1 80.2 90.2 88.9 90.4\nGMMLU-Lite 41.9 64.8 68.6 34.2 54.5 69.5 75.1\nECLeKTic 5.3 11.8 17.6 1.4 4.6 10.3 16.7\nWMT24++ 37.4 48.7 51.7 35.9 46.8 51.6 53.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 647, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8d4f9b2b-18bc-488c-bd53-74d4298adf19": {"__data__": {"id_": "8d4f9b2b-18bc-488c-bd53-74d4298adf19", "embedding": null, "metadata": {"page_label": "23", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cc17eec2-f6a5-4b74-af6a-6e4f184413fe", "node_type": "4", "metadata": {"page_label": "23", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "aa27c89f5d58e590896772eb725c95f1e1c796e3e32e4090149c6248837de26e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46bac1e0-24f2-47b7-bcc4-2658e48bb970", "node_type": "1", "metadata": {"page_label": "23", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "73f4c842b02ffe8a19e92f9befc8161bba38dfaf7c746a0d82365ebd522ca41b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "8 51.6 53.4\nTable 18|Performance of instruction fine-tuned (IT) models of different sizes on more internal and\nexternal benchmarks.\n23", "mimetype": "text/plain", "start_char_idx": 637, "end_char_idx": 771, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "db72b9e5-8186-4e5f-ad4b-89526c81d05a": {"__data__": {"id_": "db72b9e5-8186-4e5f-ad4b-89526c81d05a", "embedding": null, "metadata": {"page_label": "24", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3ce66208-b3c9-4911-9373-8a7d8db74d6b", "node_type": "4", "metadata": {"page_label": "24", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "b15cfd353e32c2259a9f2eafb52431eb464ef3f6e6c8c229c92ba618bcb637c6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nEvaluation Metric Type n-shot COT Norm\nMBPP pass@1 sampling 3-shot\nHumanEval pass@1 sampling 0-shot\nHellaSwag Accuracy scoring 10-shot Char-Len\nBoolQ Accuracy scoring 0-shot Char-Len\nPIQA Accuracy scoring 0-shot Char-Len\nSIQA Accuracy scoring 0-shot Char-Len\nTriviaQA Accuracy sampling 5-shot\nNatural Questions Accuracy sampling 5-shot\nARC-C Accuracy scoring 25-shot Char-Len\nARC-E Accuracy scoring 0-shot Char-Len\nWinoGrande Accuracy scoring 5-shot Char-Len\nBBH Accuracy sampling few-shot Yes\nDROP Token F1 score sampling 1-shot\nAGIEval Accuracy sampling 3-5-shot\nMMLU Accuracy scoring 5-shot Char-Len\nMATH Accuracy sampling 4-shot Yes\nGSM8K Accuracy sampling 8-shot Yes\nGPQA Diamond Accuracy sampling 5-shot Yes\nMMLU-Pro Accuracy sampling 5-shot Yes\nMGSM Accuracy sampling 8-shot\nFLoRes CHaRacter-level F-score sampling 1-shot\nGlobal-MMLU-Lite Accuracy scoring 5-shot Char-Len\nXQuAD CHaRacter-level F-score sampling 5-shot\nWMT24++ CHaRacter-level F-score sampling 5-shot\nECLeKTic ECLeKTic score sampling 2-shot First-line/strip\nXQuAD Indic CHaRacter-level F-score sampling 5-shot\nXOR QA IN-EN CHaRacter-level F-score sampling 5-shot\nXOR QA IN-XX CHaRacter-level F-score sampling 5-shot\nFLoRes Indic CHaRacter-level F-score sampling 5-shot\nRULER Accuracy sampling 0-shot\nMRCR MRCR score sampling few-shot\nTable 19|Details on text benchmarks. Char-Len stands for Character Length Normalization and COT\nstands for Chain-Of-Thought prompting.\n24", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1468, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6228812a-e038-4e41-8a4c-c577a413d771": {"__data__": {"id_": "6228812a-e038-4e41-8a4c-c577a413d771", "embedding": null, "metadata": {"page_label": "25", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "32d99d0a-a883-4932-bd68-796626301497", "node_type": "4", "metadata": {"page_label": "25", "file_name": "2503.19786v1.pdf", "file_path": "articles/2503.19786v1.pdf", "file_type": "application/pdf", "file_size": 3699196, "creation_date": "2025-07-07", "last_modified_date": "2025-07-07"}, "hash": "33ec8af463bf2faab696c739432b841e61a46548a6d4a0e5f97c0beec2df369c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemma 3 Technical Report\nEvaluation Metric Type n-shot\nCOCO Caption Cider score sampling 4-shot\nDocVQA ANLS score sampling 4-shot\nInfographicVQA ANLS score sampling 4-shot\nMMMU Accuracy sampling 3-shot text only\nTextVQA Accuracy sampling 4-shot\nRealWorldQA Accuracy sampling 4-shot text only\nReMI Accuracy sampling 4-shot\nAI2D Accuracy sampling 4-shot\nChartQA Accuracy sampling 4-shot\nVQA v2 Accuracy sampling 4-shot\nBLINK Accuracy sampling 0-shot\nOK-VQA Accuracy sampling 4-shot\nTallyQA Accuracy sampling 4-shot\nSpatialSense VQA Accuracy sampling 4-shot\nCountBench VQA Accuracy sampling 0-shot\nTable 20|Details on vision benchmarks. No Chain-Of-Thought prompting nor normalization.\nEvaluation Metric Type n-shot COT\nMMLU Accuracy sampling 0-shot\nMBPP pass@1 sampling 3-shot\nHumanEval pass@1 sampling 0-shot\nN2C pass@1 sampling 0-shot\nLiveCodeBench Average over 8 samples sampling 0-shot Yes\nGSM8K Accuracy sampling 0-shot Yes\nGPQA Diamond Accuracy sampling 0-shot Yes\nMATH Accuracy sampling 0-shot\nHiddenMath Accuracy sampling 0-shot\nBBH Accuracy sampling 0-shot\nBBEH Accuracy sampling 0-shot\nIFEval Accuracy sampling 0-shot\nGlobal-MMLU-lite Accuracy sampling 0-shot Yes\nECLeKTic ECLeKTic score sampling 0-shot\nWMT24++ CHaRacter-level F-score sampling 0-shot\nTable 21|Details on instruction fine-tuned (IT) benchmarks. No normalization.\n25", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1340, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}