{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2412eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Basic Setting\n",
    "\n",
    "import  load_dotenv\n",
    "load_dotenv.load_dotenv(\"../../All_LLM_tutorial/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1169a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.agent.workflow import FunctionAgent, AgentWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba56d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5f3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a699b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = FunctionAgent(\n",
    "    tools=[multiply, add],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are an agent that can perform basic mathematical operations using tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c4ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of \\( 20 + (2 \\times 4) \\) is 28.\n"
     ]
    }
   ],
   "source": [
    "response = await workflow.run(user_msg=\"What is 20+(2*4)?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd627e4",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c9a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.yahoo_finance import YahooFinanceToolSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44441dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_tools = YahooFinanceToolSpec().to_tool_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebda07a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_tools.extend([multiply, add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8baafa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current stock price of NVIDIA (NVDA) is $162.88.\n"
     ]
    }
   ],
   "source": [
    "workflow = FunctionAgent(\n",
    "    name=\"Agent\",\n",
    "    description=\"Useful for performing financial operations.\",\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    tools=finance_tools,\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    ")\n",
    "\n",
    "\n",
    "response = await workflow.run(\n",
    "    user_msg=\"What's the current stock price of NVIDIA?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77251a",
   "metadata": {},
   "source": [
    "# State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0170c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def set_name(ctx: Context, name: str) -> str:\n",
    "    state = await ctx.store.get(\"state\")\n",
    "    state[\"name\"] = name\n",
    "    await ctx.store.set(\"state\", state)\n",
    "    return f\"Name set to {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ba8fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_data': {'memory': '{\"__is_component\": true, \"value\": {\"chat_store\": {\"store\": {\"chat_history\": [{\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Hi, my name is Laurie!\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Hello Laurie! How can I assist you today?\"}]}, {\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"What\\'s my name?\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Your name is Laurie! How can I help you today, Laurie?\"}]}]}, \"class_name\": \"SimpleChatStore\"}, \"chat_store_key\": \"chat_history\", \"token_limit\": 96000, \"class_name\": \"ChatMemoryBuffer\"}, \"qualified_name\": \"llama_index.core.memory.chat_memory_buffer.ChatMemoryBuffer\"}',\n",
       "  'state': '{}',\n",
       "  'formatted_input_with_state': 'false',\n",
       "  'user_msg_str': '\"What\\'s my name?\"',\n",
       "  'scratchpad': '[]',\n",
       "  'current_tool_calls': '[]'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_dict[\"state\"][\"state_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object InMemoryStateStore.get at 0x7efc2dc84eb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.store.get(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = AgentWorkflow.from_tools_or_functions(\n",
    "    [set_name],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can set a name.\",\n",
    "    initial_state={\"name\": \"unset\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name has been set to \"unset.\"\n"
     ]
    }
   ],
   "source": [
    "ctx = Context(workflow)\n",
    "\n",
    "# check if it knows a name before setting it\n",
    "response = await workflow.run(user_msg=\"What's my name?\", ctx=ctx)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a583969f",
   "metadata": {},
   "source": [
    "## How to check State!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_data': {'memory': '{\"__is_component\": true, \"value\": {\"chat_store\": {\"store\": {\"chat_history\": [{\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Current state:\\\\n{\\'name\\': \\'unset\\'}\\\\n\\\\nCurrent message:\\\\nWhat\\'s my name?\\\\n\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": [{\"index\": 0, \"id\": \"call_fb8Okgq9sqpzH7Jm6dA1amwK\", \"function\": {\"arguments\": \"{\\\\\"name\\\\\":\\\\\"unset\\\\\"}\", \"name\": \"set_name\"}, \"type\": \"function\"}]}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"\"}]}, {\"role\": \"tool\", \"additional_kwargs\": {\"tool_call_id\": \"call_fb8Okgq9sqpzH7Jm6dA1amwK\"}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Name set to unset\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Your name has been set to \\\\\"unset.\\\\\"\"}]}]}, \"class_name\": \"SimpleChatStore\"}, \"chat_store_key\": \"chat_history\", \"token_limit\": 96000, \"class_name\": \"ChatMemoryBuffer\"}, \"qualified_name\": \"llama_index.core.memory.chat_memory_buffer.ChatMemoryBuffer\"}',\n",
       "  'agents': '[\"Agent\"]',\n",
       "  'can_handoff_to': '{\"Agent\": null}',\n",
       "  'state': '{\"name\": \"unset\"}',\n",
       "  'current_agent_name': '\"Agent\"',\n",
       "  'handoff_output_prompt': '\"Agent {to_agent} is now handling the request due to the following reason: {reason}.\\\\nPlease continue with the current request.\"',\n",
       "  'formatted_input_with_state': 'true',\n",
       "  'user_msg_str': '\"What\\'s my name?\"',\n",
       "  'scratchpad': '[]',\n",
       "  'num_tool_calls': '1',\n",
       "  'current_tool_calls': '[]'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_dict = ctx.to_dict(serializer=JsonSerializer())\n",
    "ctx_dict[\"state\"][\"state_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name has been updated to \"Laurie.\"\n"
     ]
    }
   ],
   "source": [
    "response2 = await workflow.run(user_msg=\"My name is Laurie\", ctx=ctx)\n",
    "print(str(response2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_data': {'memory': '{\"__is_component\": true, \"value\": {\"chat_store\": {\"store\": {\"chat_history\": [{\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Current state:\\\\n{\\'name\\': \\'unset\\'}\\\\n\\\\nCurrent message:\\\\nWhat\\'s my name?\\\\n\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": [{\"index\": 0, \"id\": \"call_fb8Okgq9sqpzH7Jm6dA1amwK\", \"function\": {\"arguments\": \"{\\\\\"name\\\\\":\\\\\"unset\\\\\"}\", \"name\": \"set_name\"}, \"type\": \"function\"}]}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"\"}]}, {\"role\": \"tool\", \"additional_kwargs\": {\"tool_call_id\": \"call_fb8Okgq9sqpzH7Jm6dA1amwK\"}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Name set to unset\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Your name has been set to \\\\\"unset.\\\\\"\"}]}, {\"role\": \"user\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Current state:\\\\n{\\'name\\': \\'unset\\'}\\\\n\\\\nCurrent message:\\\\nMy name is Laurie\\\\n\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {\"tool_calls\": [{\"index\": 0, \"id\": \"call_EFjO81GSycZd03cMycCuVA28\", \"function\": {\"arguments\": \"{\\\\\"name\\\\\":\\\\\"Laurie\\\\\"}\", \"name\": \"set_name\"}, \"type\": \"function\"}]}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"\"}]}, {\"role\": \"tool\", \"additional_kwargs\": {\"tool_call_id\": \"call_EFjO81GSycZd03cMycCuVA28\"}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Name set to Laurie\"}]}, {\"role\": \"assistant\", \"additional_kwargs\": {}, \"blocks\": [{\"block_type\": \"text\", \"text\": \"Your name has been updated to \\\\\"Laurie.\\\\\"\"}]}]}, \"class_name\": \"SimpleChatStore\"}, \"chat_store_key\": \"chat_history\", \"token_limit\": 96000, \"class_name\": \"ChatMemoryBuffer\"}, \"qualified_name\": \"llama_index.core.memory.chat_memory_buffer.ChatMemoryBuffer\"}',\n",
       "  'agents': '[\"Agent\"]',\n",
       "  'can_handoff_to': '{\"Agent\": null}',\n",
       "  'state': '{\"name\": \"Laurie\"}',\n",
       "  'current_agent_name': '\"Agent\"',\n",
       "  'handoff_output_prompt': '\"Agent {to_agent} is now handling the request due to the following reason: {reason}.\\\\nPlease continue with the current request.\"',\n",
       "  'formatted_input_with_state': 'true',\n",
       "  'user_msg_str': '\"My name is Laurie\"',\n",
       "  'scratchpad': '[]',\n",
       "  'num_tool_calls': '1',\n",
       "  'current_tool_calls': '[]'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_dict = ctx.to_dict(serializer=JsonSerializer())\n",
    "ctx_dict[\"state\"][\"state_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name as stored in state:  Laurie\n"
     ]
    }
   ],
   "source": [
    "state = await ctx.store.get(\"state\")\n",
    "print(\"Name as stored in state: \", state[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59720113",
   "metadata": {},
   "source": [
    "# Streaming?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9521772",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilyToolSpec(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd1ca130",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = FunctionAgent(\n",
    "    tools=tavily_tool.to_tool_list(),\n",
    "    llm=llm,\n",
    "    system_prompt=\"You're a helpful assistant that can search the web for information.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57f2b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import AgentStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91b8f403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is generally mild. Here are some details:\n",
      "\n",
      "- **Temperature**: The high is around 20°C (68°F) and the low is about 14°C (57°F).\n",
      "- **Conditions**: The weather is partly cloudy with some sunny intervals.\n",
      "- **Winds**: Winds are coming from the west at 10 to 20 mph.\n",
      "\n",
      "For more detailed forecasts, you can check out [The Weather Channel](https://weather.com/weather/today/l/USCA0987:1:US) or [Weather25](https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=October)."
     ]
    }
   ],
   "source": [
    "handler = workflow.run(user_msg=\"What's the weather like in San Francisco?\")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, AgentStream):\n",
    "        print(event.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a044e18",
   "metadata": {},
   "source": [
    "# HITL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d1b35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "998b15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "\n",
    "async def dangerous_task(ctx: Context) -> str:\n",
    "    \"\"\"A dangerous task that requires human confirmation.\"\"\"\n",
    "\n",
    "    # emit a waiter event (InputRequiredEvent here)\n",
    "    # and wait until we see a HumanResponseEvent\n",
    "    question = \"Are you sure you want to proceed? \"\n",
    "    response = await ctx.wait_for_event(\n",
    "        HumanResponseEvent,\n",
    "        waiter_id=question,\n",
    "        waiter_event=InputRequiredEvent(\n",
    "            prefix=question,\n",
    "            user_name=\"Laurie\",\n",
    "        ),\n",
    "        requirements={\"user_name\": \"Laurie\"},\n",
    "    )\n",
    "\n",
    "    # act on the input from the event\n",
    "    if response.response.strip().lower() == \"yes\":\n",
    "        return \"Dangerous task completed successfully.\"\n",
    "    else:\n",
    "        return \"Dangerous task aborted.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6a9b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = FunctionAgent(\n",
    "    tools=[dangerous_task],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that can perform dangerous tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1918f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurie\n",
      "The dangerous task has been aborted. If you would like to proceed with it, please confirm your decision.\n"
     ]
    }
   ],
   "source": [
    "handler = workflow.run(user_msg=\"I want to proceed with the dangerous task.\")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        # capture keyboard input\n",
    "        response = input(event.prefix)\n",
    "        # send our response back\n",
    "        handler.ctx.send_event(\n",
    "            HumanResponseEvent(\n",
    "                response=response,\n",
    "                user_name=event.user_name,\n",
    "            )\n",
    "        )\n",
    "\n",
    "response = await handler\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5afa5d",
   "metadata": {},
   "source": [
    "# Multi Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b39a50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Make tool for acting below tab\n",
    "# Multi-Agent Tools\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "def search_web(query: str, ctx: Context) -> str:\n",
    "    \"\"\"웹에서 주어진 쿼리에 대한 정보를 검색합니다.\"\"\"\n",
    "    # 실제 구현에서는 실제 웹 검색 API를 사용할 수 있습니다\n",
    "    # 여기서는 시뮬레이션 데이터를 반환합니다\n",
    "    search_results = {\n",
    "        \"history of the web\": {\n",
    "            \"timeline\": \"1989년 팀 버너스리가 WWW 제안, 1990년 첫 웹 브라우저 개발, 1993년 모자이크 브라우저 출시\",\n",
    "            \"key_figures\": \"팀 버너스리, 마크 안드리슨\",\n",
    "            \"technologies\": \"HTML, HTTP, URL\"\n",
    "        },\n",
    "        \"web development\": {\n",
    "            \"evolution\": \"정적 웹 → 동적 웹 → 웹 2.0 → 모바일 웹 → 현대 웹\",\n",
    "            \"frameworks\": \"React, Vue, Angular\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 검색 결과를 기반으로 답변 생성\n",
    "    if \"history\" in query.lower() and \"web\" in query.lower():\n",
    "        return f\"검색 결과: {search_results['history of the web']}\"\n",
    "    elif \"web\" in query.lower():\n",
    "        return f\"검색 결과: {search_results['web development']}\"\n",
    "    else:\n",
    "        return f\"'{query}'에 대한 일반적인 검색 결과를 찾았습니다.\"\n",
    "\n",
    "async def record_notes(ctx: Context, topic: str, content: str) -> str:\n",
    "    \"\"\"연구 노트를 기록하고 상태에 저장합니다.\"\"\"\n",
    "    state = await ctx.store.get(\"state\")\n",
    "    \n",
    "    if \"research_notes\" not in state:\n",
    "        state[\"research_notes\"] = {}\n",
    "    \n",
    "    # 노트 추가\n",
    "    state[\"research_notes\"][topic] = content\n",
    "    await ctx.store.set(\"state\", state)\n",
    "    \n",
    "    return f\"'{topic}' 주제에 대한 노트가 기록되었습니다: {content[:100]}...\"\n",
    "\n",
    "async def write_report(ctx: Context, topic: str) -> str:\n",
    "    \"\"\"기록된 노트를 바탕으로 마크다운 리포트를 작성합니다.\"\"\"\n",
    "    state = await ctx.store.get(\"state\")\n",
    "    \n",
    "    research_notes = state.get(\"research_notes\", {})\n",
    "    \n",
    "    if not research_notes:\n",
    "        return \"리포트를 작성하기 위한 연구 노트가 없습니다. 먼저 연구를 진행해주세요.\"\n",
    "    \n",
    "    # 마크다운 리포트 생성\n",
    "    report = f\"# {topic} 리포트\\n\\n\"\n",
    "    \n",
    "    for note_topic, note_content in research_notes.items():\n",
    "        report += f\"## {note_topic}\\n\\n\"\n",
    "        report += f\"{note_content}\\n\\n\"\n",
    "    \n",
    "    report += \"## 결론\\n\\n\"\n",
    "    report += \"이 연구를 통해 웹의 역사와 발전 과정을 살펴보았습니다.\\n\"\n",
    "    \n",
    "    # 상태에 리포트 저장\n",
    "    state[\"report_content\"] = report\n",
    "    await ctx.store.set(\"state\", state)\n",
    "    \n",
    "    return f\"'{topic}' 리포트가 작성되었습니다:\\n\\n{report}\"\n",
    "\n",
    "async def review_report(ctx: Context) -> str:\n",
    "    \"\"\"작성된 리포트를 검토하고 피드백을 제공합니다.\"\"\"\n",
    "    state = await ctx.store.get(\"state\")\n",
    "    \n",
    "    report_content = state.get(\"report_content\", \"\")\n",
    "    \n",
    "    if not report_content or report_content == \"Not written yet.\":\n",
    "        return \"검토할 리포트가 없습니다. 먼저 리포트를 작성해주세요.\"\n",
    "    \n",
    "    # 리포트 검토\n",
    "    word_count = len(report_content.split())\n",
    "    section_count = report_content.count(\"##\")\n",
    "    \n",
    "    feedback = []\n",
    "    \n",
    "    if word_count < 100:\n",
    "        feedback.append(\"리포트가 너무 짧습니다. 더 자세한 내용을 추가해주세요.\")\n",
    "    \n",
    "    if section_count < 2:\n",
    "        feedback.append(\"리포트에 더 많은 섹션을 추가하여 구조를 개선해주세요.\")\n",
    "    \n",
    "    if not feedback:\n",
    "        feedback.append(\"리포트가 잘 작성되었습니다. 좋은 구조와 내용을 가지고 있습니다.\")\n",
    "    \n",
    "    review_text = \"\\n\".join(feedback)\n",
    "    \n",
    "    # 상태에 검토 결과 저장\n",
    "    state[\"review\"] = review_text\n",
    "    await ctx.store.set(\"state\", state)\n",
    "    \n",
    "    return f\"리포트 검토 완료:\\n\\n{review_text}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85423a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review of the report on the history of the web indicates that it is too short and requires more detailed content. Would you like me to assist in expanding the report with additional information?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow, FunctionAgent\n",
    "\n",
    "# --- create our specialist agents ------------------------------------------------\n",
    "research_agent = FunctionAgent(\n",
    "    name=\"ResearchAgent\",\n",
    "    description=\"Search the web and record notes.\",\n",
    "    system_prompt=\"You are a researcher… hand off to WriteAgent when ready.\",\n",
    "    llm=llm,\n",
    "    tools=[search_web, record_notes],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "write_agent = FunctionAgent(\n",
    "    name=\"WriteAgent\",\n",
    "    description=\"Writes a markdown report from the notes.\",\n",
    "    system_prompt=\"You are a writer… ask ReviewAgent for feedback when done.\",\n",
    "    llm=llm,\n",
    "    tools=[write_report],\n",
    "    can_handoff_to=[\"ReviewAgent\", \"ResearchAgent\"],\n",
    ")\n",
    "\n",
    "review_agent = FunctionAgent(\n",
    "    name=\"ReviewAgent\",\n",
    "    description=\"Reviews a report and gives feedback.\",\n",
    "    system_prompt=\"You are a reviewer…\",  # etc.\n",
    "    llm=llm,\n",
    "    tools=[review_report],\n",
    "    can_handoff_to=[\"WriteAgent\"],\n",
    ")\n",
    "\n",
    "# --- wire them together ----------------------------------------------------------\n",
    "agent_workflow = AgentWorkflow(\n",
    "    agents=[research_agent, write_agent, review_agent],\n",
    "    root_agent=research_agent.name,\n",
    "    initial_state={\n",
    "        \"research_notes\": {},\n",
    "        \"report_content\": \"Not written yet.\",\n",
    "        \"review\": \"Review required.\",\n",
    "    },\n",
    ")\n",
    "\n",
    "resp = await agent_workflow.run(\n",
    "    user_msg=\"Write me a report on the history of the web …\"\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "990a6b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== 최종 상태 ===\n",
      "연구 노트 개수: 3\n",
      "리포트 길이: 546\n",
      "검토 상태: 리포트가 너무 짧습니다. 더 자세한 내용을 추가해주세요.\n",
      "\\n=== 연구 노트 ===\n",
      "주제: history of the web\n",
      "내용: - 1989: Tim Berners-Lee proposed the World Wide Web.\n",
      "- 1990: The first web browser was developed.\n",
      "- 1993: The Mosaic browser was released.\n",
      "--------------------------------------------------\n",
      "주제: key figures in the history of the web\n",
      "내용: - Tim Berners-Lee: Inventor of the World Wide Web.\n",
      "- Marc Andreessen: Co-author of Mosaic, the first widely used web browser.\n",
      "--------------------------------------------------\n",
      "주제: technologies in the history of the web\n",
      "내용: - HTML (HyperText Markup Language)\n",
      "- HTTP (HyperText Transfer Protocol)\n",
      "- URL (Uniform Resource Locator)\n",
      "--------------------------------------------------\n",
      "\\n=== 최종 리포트 ===\n",
      "# history of the web 리포트\n",
      "\n",
      "## history of the web\n",
      "\n",
      "- 1989: Tim Berners-Lee proposed the World Wide Web.\n",
      "- 1990: The first web browser was developed.\n",
      "- 1993: The Mosaic browser was released.\n",
      "\n",
      "## key figures in the history of the web\n",
      "\n",
      "- Tim Berners-Lee: Inventor of the World Wide Web.\n",
      "- Marc Andreessen: Co-author of Mosaic, the first widely used web browser.\n",
      "\n",
      "## technologies in the history of the web\n",
      "\n",
      "- HTML (HyperText Markup Language)\n",
      "- HTTP (HyperText Transfer Protocol)\n",
      "- URL (Uniform Resource Locator)\n",
      "\n",
      "## 결론\n",
      "\n",
      "이 연구를 통해 웹의 역사와 발전 과정을 살펴보았습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 워크플로우 상태 확인\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent_workflow)\n",
    "await agent_workflow.run(user_msg=\"웹의 역사에 대한 리포트를 작성해주세요.\", ctx=ctx)\n",
    "\n",
    "# 최종 상태 확인\n",
    "final_state = await ctx.store.get(\"state\")\n",
    "print(\"\\\\n=== 최종 상태 ===\")\n",
    "print(f\"연구 노트 개수: {len(final_state.get('research_notes', {}))}\")\n",
    "print(f\"리포트 길이: {len(final_state.get('report_content', ''))}\")\n",
    "print(f\"검토 상태: {final_state.get('review', 'No review')}\")\n",
    "\n",
    "# 연구 노트 확인\n",
    "print(\"\\\\n=== 연구 노트 ===\")\n",
    "for topic, content in final_state.get('research_notes', {}).items():\n",
    "    print(f\"주제: {topic}\")\n",
    "    print(f\"내용: {content}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 최종 리포트 확인\n",
    "print(\"\\\\n=== 최종 리포트 ===\")\n",
    "print(final_state.get('report_content', 'No report generated'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035790f",
   "metadata": {},
   "source": [
    "# Orchestration Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "# assume research_agent / write_agent / review_agent defined as before\n",
    "# except we really only need the `search_web` tool at a minimum\n",
    "\n",
    "\n",
    "async def call_research_agent(ctx: Context, prompt: str) -> str:\n",
    "    \"\"\"Useful for recording research notes based on a specific prompt.\"\"\"\n",
    "    result = await research_agent.run(\n",
    "        user_msg=f\"Write some notes about the following: {prompt}\"\n",
    "    )\n",
    "\n",
    "    state = await ctx.store.get(\"state\")\n",
    "    state[\"research_notes\"].append(str(result))\n",
    "    await ctx.store.set(\"state\", state)\n",
    "\n",
    "    return str(result)\n",
    "\n",
    "\n",
    "async def call_write_agent(ctx: Context) -> str:\n",
    "    \"\"\"Useful for writing a report based on the research notes or revising the report based on feedback.\"\"\"\n",
    "    state = await ctx.store.get(\"state\")\n",
    "    notes = state.get(\"research_notes\", None)\n",
    "    if not notes:\n",
    "        return \"No research notes to write from.\"\n",
    "\n",
    "    user_msg = f\"Write a markdown report from the following notes. Be sure to output the report in the following format: <report>...</report>:\\n\\n\"\n",
    "\n",
    "    # Add the feedback to the user message if it exists\n",
    "    feedback = state.get(\"review\", None)\n",
    "    if feedback:\n",
    "        user_msg += f\"<feedback>{feedback}</feedback>\\n\\n\"\n",
    "\n",
    "    # Add the research notes to the user message\n",
    "    notes = \"\\n\\n\".join(notes)\n",
    "    user_msg += f\"<research_notes>{notes}</research_notes>\\n\\n\"\n",
    "\n",
    "    # Run the write agent\n",
    "    result = await write_agent.run(user_msg=user_msg)\n",
    "    report = re.search(r\"<report>(.*)</report>\", str(result), re.DOTALL).group(\n",
    "        1\n",
    "    )\n",
    "    state[\"report_content\"] = str(report)\n",
    "    await ctx.store.set(\"state\", state)\n",
    "\n",
    "    return str(report)\n",
    "\n",
    "\n",
    "async def call_review_agent(ctx: Context) -> str:\n",
    "    \"\"\"Useful for reviewing the report and providing feedback.\"\"\"\n",
    "    state = await ctx.store.get(\"state\")\n",
    "    report = state.get(\"report_content\", None)\n",
    "    if not report:\n",
    "        return \"No report content to review.\"\n",
    "\n",
    "    result = await review_agent.run(\n",
    "        user_msg=f\"Review the following report: {report}\"\n",
    "    )\n",
    "    state[\"review\"] = result\n",
    "    await ctx.store.set(\"state\", state)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "orchestrator = FunctionAgent(\n",
    "    system_prompt=(\n",
    "        \"You are an expert in the field of report writing. \"\n",
    "        \"You are given a user request and a list of tools that can help with the request. \"\n",
    "        \"You are to orchestrate the tools to research, write, and review a report on the given topic. \"\n",
    "        \"Once the review is positive, you should notify the user that the report is ready to be accessed.\"\n",
    "        \"should end before 30sec\"\n",
    "    ),\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    tools=[\n",
    "        call_research_agent,\n",
    "        call_write_agent,\n",
    "        call_review_agent,\n",
    "    ],\n",
    "    initial_state={\n",
    "        \"research_notes\": [],\n",
    "        \"report_content\": None,\n",
    "        \"review\": None,\n",
    "    },\n",
    "    timeout=60,\n",
    ")\n",
    "\n",
    "response = await orchestrator.run(\n",
    "    user_msg=\"Write me a report on the history of the web …\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
