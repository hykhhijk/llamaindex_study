{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "875e1e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Basic Setting\n",
    "\n",
    "import  load_dotenv\n",
    "load_dotenv.load_dotenv(\"../../All_LLM_tutorial/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba5de7",
   "metadata": {},
   "source": [
    "### Huggingface Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c180bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# loads https://huggingface.co/BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c33eca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "[-0.02858859673142433, 0.03531505912542343, -0.013649016618728638, -0.02296101674437523, 0.0070844353176653385]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed_model.get_text_embedding(\"테스트용 문장\")\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])\n",
    "\n",
    "embedding2 = embed_model.get_text_embedding(\"Test sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80c87d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7525461106422485)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model.similarity(embeddings, embedding2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80215d42",
   "metadata": {},
   "source": [
    "### Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4db547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install sentence-transformers[openvino]\n",
    "\n",
    "# # loads BAAI/bge-small-en-v1.5 with the openvino backend\n",
    "# embed_model = HuggingFaceEmbedding(\n",
    "#     model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "#     device=\"cpu\",\n",
    "#     backend=\"openvino\",  # OpenVINO is very strong on CPUs\n",
    "#     revision=\"refs/pr/16\",  # BAAI/bge-small-en-v1.5 itself doesn't have an OpenVINO model currently, but there's a PR with it that we can load: https://huggingface.co/BAAI/bge-small-en-v1.5/discussions/16\n",
    "#     model_kwargs={\n",
    "#         \"file_name\": \"openvino_model_qint8_quantized.xml\"\n",
    "#     },  # If we're using an optimized/quantized model, we need to specify the file name like this\n",
    "# )\n",
    "# test_embeds = embed_model.get_text_embedding(\"Hello World!\")\n",
    "\n",
    "# Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2136f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6d551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f06931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126589e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
